{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Installation \u00b6 A lightweight node.js boilerplate framework for serverless architecture \u00b6 Bootstrap your next serverless microservice with a light-weight node.js app built on top of the Serverless Framework on AWS. Why Lesgo! Framework \u00b6 Like any other frameworks out there, we built this Framework because we couldn't find one that fits our needs. We believe that a framework for the Serverless Architecture should fit the following criteria: Super lightweight . The bundled lambda function should only bundle what is necessarily required by the function, and nothing else. This is why we chose the Serverless Framework as the basic building block for this framework. It provides the necessary tools to build, bundle, and deploy direct to AWS via CloudFormation, while still allowing the option to bundle each function individually. Easy to understand file structure . Most of our file structure, scripts, and helper functions is inspired from the Laravel Framework. The primary reason being that all the original developers and current maintainers have years of experience building applications on Taylor Otwell's Laravel Framework. If you know Laravel, you will know Lesgo! Highly adaptable for any use case . We have built multiple microservices for the last 3 years from a simple \"Unique Name Generator\", to a process-intensive \"Photo Processor\" and \"Image Moderation\", to complex projects building a Social Network App using this very same framework! Continous upgrades . As long as we continue to use this framework, we will continue to maintain and expand its functionalities. This framework will continue to grow with us. We take the learnings from our other microservices and upgrade this framework accordingly. Quick Start \u00b6 Prerequisites Install Serverless Framework globally with: npm install -g serverless . Refer to https://serverless.com/framework/docs/getting-started/ for additional info. Create Serverless project: sls create --template-url https://github.com/reflex-media/lesgo-lite/tree/master --path my-service cd my-service Install dependencies: npm install Start local: npm start Access local url via browser or Postman: http://localhost:8181/ping . Configuration \u00b6 There are 2 levels of configurations for the Lesgo! framework. The project (serverless) configurations are stored in config/ directory as .yml files. These configuration files affect your project set up and build. The application configurations are stored in src/config/ directory as .js files (We'll move to TypeScript soon, we promise!). These are application/business specific configurations. Each configuration is documented below, so feel free to look through the files and get familiar with the options relevant to you. Environment Configuration \u00b6 It is often helpful to have different configuration values based on the environment where the application is running. For example, you may wish to use a different SQS queue locally than you do on your production server. To make this happen, Lesgo! uses the Serverless DOTenv plugin. DOTenv files are stored in config/environments/ directory. The supported environments are currently local , dev , sandbox , prod . These environment files can be committed to the source control. To overwrite for your local build, you may create a local DOTenv as such example: .env.dev.local . This will allow you to overwrite the existing .env.dev without having to commit it. Available Environment Configurations \u00b6 # Declare the environment to deploy to APP_ENV = \"dev\" # Enable/disable debug mode APP_DEBUG =true # Determine the region to deploy to AWS_ACCOUNT_REGION = \"us-west-1\" # This name needs to match the aws credentials profile on your local machine AWS_ACCOUNT_PROFILE = \"slsDevProfile\" # Set the default timeout for all lambda functions AWS_LAMBDA_TIMEOUT =3 # Set the default memory size for all lambda functions AWS_LAMBDA_MEMORY_SIZE =128 # Set the default retention period for all cloudwatch logs AWS_LOG_RETENTION_DAYS =7 # Maximum size before gzip compression for response AWS_APIGATEWAY_COMPRESSION_MAX_BYTES =","title":"Installation"},{"location":"#installation","text":"","title":"Installation"},{"location":"#a-lightweight-nodejs-boilerplate-framework-for-serverless-architecture","text":"Bootstrap your next serverless microservice with a light-weight node.js app built on top of the Serverless Framework on AWS.","title":"A lightweight node.js boilerplate framework for serverless architecture"},{"location":"#why-lesgo-framework","text":"Like any other frameworks out there, we built this Framework because we couldn't find one that fits our needs. We believe that a framework for the Serverless Architecture should fit the following criteria: Super lightweight . The bundled lambda function should only bundle what is necessarily required by the function, and nothing else. This is why we chose the Serverless Framework as the basic building block for this framework. It provides the necessary tools to build, bundle, and deploy direct to AWS via CloudFormation, while still allowing the option to bundle each function individually. Easy to understand file structure . Most of our file structure, scripts, and helper functions is inspired from the Laravel Framework. The primary reason being that all the original developers and current maintainers have years of experience building applications on Taylor Otwell's Laravel Framework. If you know Laravel, you will know Lesgo! Highly adaptable for any use case . We have built multiple microservices for the last 3 years from a simple \"Unique Name Generator\", to a process-intensive \"Photo Processor\" and \"Image Moderation\", to complex projects building a Social Network App using this very same framework! Continous upgrades . As long as we continue to use this framework, we will continue to maintain and expand its functionalities. This framework will continue to grow with us. We take the learnings from our other microservices and upgrade this framework accordingly.","title":"Why Lesgo! Framework"},{"location":"#quick-start","text":"Prerequisites Install Serverless Framework globally with: npm install -g serverless . Refer to https://serverless.com/framework/docs/getting-started/ for additional info. Create Serverless project: sls create --template-url https://github.com/reflex-media/lesgo-lite/tree/master --path my-service cd my-service Install dependencies: npm install Start local: npm start Access local url via browser or Postman: http://localhost:8181/ping .","title":"Quick Start"},{"location":"#configuration","text":"There are 2 levels of configurations for the Lesgo! framework. The project (serverless) configurations are stored in config/ directory as .yml files. These configuration files affect your project set up and build. The application configurations are stored in src/config/ directory as .js files (We'll move to TypeScript soon, we promise!). These are application/business specific configurations. Each configuration is documented below, so feel free to look through the files and get familiar with the options relevant to you.","title":"Configuration"},{"location":"#environment-configuration","text":"It is often helpful to have different configuration values based on the environment where the application is running. For example, you may wish to use a different SQS queue locally than you do on your production server. To make this happen, Lesgo! uses the Serverless DOTenv plugin. DOTenv files are stored in config/environments/ directory. The supported environments are currently local , dev , sandbox , prod . These environment files can be committed to the source control. To overwrite for your local build, you may create a local DOTenv as such example: .env.dev.local . This will allow you to overwrite the existing .env.dev without having to commit it.","title":"Environment Configuration"},{"location":"#available-environment-configurations","text":"# Declare the environment to deploy to APP_ENV = \"dev\" # Enable/disable debug mode APP_DEBUG =true # Determine the region to deploy to AWS_ACCOUNT_REGION = \"us-west-1\" # This name needs to match the aws credentials profile on your local machine AWS_ACCOUNT_PROFILE = \"slsDevProfile\" # Set the default timeout for all lambda functions AWS_LAMBDA_TIMEOUT =3 # Set the default memory size for all lambda functions AWS_LAMBDA_MEMORY_SIZE =128 # Set the default retention period for all cloudwatch logs AWS_LOG_RETENTION_DAYS =7 # Maximum size before gzip compression for response AWS_APIGATEWAY_COMPRESSION_MAX_BYTES =","title":"Available Environment Configurations"},{"location":"404/","text":"404 Page Not Found \u00b6 The page you are looking for does not exist. Return to homepage .","title":"404 Page Not Found"},{"location":"404/#404-page-not-found","text":"The page you are looking for does not exist. Return to homepage .","title":"404 Page Not Found"},{"location":"advance/cache/","text":"Cache \u00b6 Lesgo! uses AWS ElastiCache for caching. Configuration \u00b6 This is configurable in the src/config/cache.js . Or copy this file to that path. export default { default : \"memcached\" , connections : { memcached : { url : process . env . ELASTICACHE_MEMCACHED_URL || null , options : { autoDiscover : true , autoDiscoverInterval : 60000 , autoDiscoverOverridesRemove : false } } } }; ElastiCache is disabled by default. To enable ElastiCache, follow the steps below. Uncomment elastiCache.yml resource in serverless.yml resources: - ${file(${self:custom.path.resources}/elastiCache.yml)} Deploy application and retrieve ElastiCache node Endpoint on AWS Console. yarn deploy -s development Update relevant environment file in config/environments/ directory. ELASTICACHE_MEMCACHED_URL = \"INSERT_ELASTICACHE_NODE_ENDPOINT_HERE\" Deploy your application again and you may now use ElastiCache. Cache Usage \u00b6 Import the cache module from Utils/cache . To test the sample usage, uncomment samples.yml function in serverless.yml and deploy the application to a development environment. Retrieving items from the cache \u00b6 You may use the get method on the cache util to fetch items from the cache. import cache from \"Utils/cache\" ; const cacheKey = \"foo\" ; const data = await cache . get ( cacheKey ); Test sample usage with this url endpoint /samples/cache?method=get&key=sampleCacheKey . Storing items to the cache \u00b6 You may use the set method on the cache util to store items to the cache. import cache from \"Utils/cache\" ; const cacheKey = \"foo\" ; const cacheValue = \"bar\" ; const cacheLifetimeInSeconds = 10 ; const data = await cache . set ( cacheKey , cacheValue , cacheLifetimeInSeconds ); Test sample usage with this url endpoint /samples/cache?method=set&key=sampleCacheKey&value=sampleCacheValue . Deleting items from the cache \u00b6 You may use the del method on the cache util to delete items from the cache. import cache from \"Utils/cache\" ; const cacheKey = \"foo\" ; const data = await cache . del ( cacheKey ); Test sample usage with this url endpoint /samples/cache?method=del&key=sampleCacheKey .","title":"Cache"},{"location":"advance/cache/#cache","text":"Lesgo! uses AWS ElastiCache for caching.","title":"Cache"},{"location":"advance/cache/#configuration","text":"This is configurable in the src/config/cache.js . Or copy this file to that path. export default { default : \"memcached\" , connections : { memcached : { url : process . env . ELASTICACHE_MEMCACHED_URL || null , options : { autoDiscover : true , autoDiscoverInterval : 60000 , autoDiscoverOverridesRemove : false } } } }; ElastiCache is disabled by default. To enable ElastiCache, follow the steps below. Uncomment elastiCache.yml resource in serverless.yml resources: - ${file(${self:custom.path.resources}/elastiCache.yml)} Deploy application and retrieve ElastiCache node Endpoint on AWS Console. yarn deploy -s development Update relevant environment file in config/environments/ directory. ELASTICACHE_MEMCACHED_URL = \"INSERT_ELASTICACHE_NODE_ENDPOINT_HERE\" Deploy your application again and you may now use ElastiCache.","title":"Configuration"},{"location":"advance/cache/#cache-usage","text":"Import the cache module from Utils/cache . To test the sample usage, uncomment samples.yml function in serverless.yml and deploy the application to a development environment.","title":"Cache Usage"},{"location":"advance/cache/#retrieving-items-from-the-cache","text":"You may use the get method on the cache util to fetch items from the cache. import cache from \"Utils/cache\" ; const cacheKey = \"foo\" ; const data = await cache . get ( cacheKey ); Test sample usage with this url endpoint /samples/cache?method=get&key=sampleCacheKey .","title":"Retrieving items from the cache"},{"location":"advance/cache/#storing-items-to-the-cache","text":"You may use the set method on the cache util to store items to the cache. import cache from \"Utils/cache\" ; const cacheKey = \"foo\" ; const cacheValue = \"bar\" ; const cacheLifetimeInSeconds = 10 ; const data = await cache . set ( cacheKey , cacheValue , cacheLifetimeInSeconds ); Test sample usage with this url endpoint /samples/cache?method=set&key=sampleCacheKey&value=sampleCacheValue .","title":"Storing items to the cache"},{"location":"advance/cache/#deleting-items-from-the-cache","text":"You may use the del method on the cache util to delete items from the cache. import cache from \"Utils/cache\" ; const cacheKey = \"foo\" ; const data = await cache . del ( cacheKey ); Test sample usage with this url endpoint /samples/cache?method=del&key=sampleCacheKey .","title":"Deleting items from the cache"},{"location":"advance/full-text-search/","text":"Full-Text Search \u00b6 Lesgo! is pre-configured with AWS Elasticsearch for full-text search. Configuration \u00b6 The elasticsearch configuration for your application is located at src/config/elasticsearch.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # Elasticsearch index name to use ES_INDEX = \"\" # Elasticsaerch mapping type # Empty this line if you are using Elasticsearch \u2264 6 ES_TYPE = \"_doc\" # Elasticsearch node URL ES_NODE = \"\" # Elasticsearch region name ES_REGION = \"\" Basic Usage \u00b6 To run a basic query, you may use the search method on the Utils/es : import es from \"Utils/elasticsearch\" ; const response = await es (). search ({ query : { match : { quote : \"winter\" , }, }, }); /** { \"body\": { \"took\": 22, \"timed_out\": false, \"_shards\": { \"total\": 6, \"successful\": 6, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 10, \"max_score\": null, \"hits\": [ { \"_index\": \"test_search_20210628\", \"_type\": \"profiles\", \"_id\": \"3692613\", \"_score\": null, \"_source\": { \"username\": \"test_user\", \"language\": \"en\", \"age\": 32, \"height\": \"157\" }, \"sort\": [ 1637620268000 ] } ... ] } } } */ Advanced Query \u00b6 import es from \"Utils/elasticsearch\" ; const response = await es (). search ({ from : 0 , size : 4 , query : { bool : { must : [ { match : { account_type : 2 , }, }, ], must_not : { terms : { account_id : [ 3627950 ], }, }, filter : [ { geo_distance : { distance : \"50mi\" , distance_type : \"arc\" , location : { lat : 37.7749295 , lon : - 122.4194155 , }, }, }, ], }, }, sort : [ { last_activity_dt : { order : \"desc\" , }, }, ], }); /** { \"body\": { \"took\": 22, \"timed_out\": false, \"_shards\": { \"total\": 6, \"successful\": 6, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 10, \"max_score\": null, \"hits\": [ { \"_index\": \"test_search_20210628\", \"_type\": \"profiles\", \"_id\": \"3692613\", \"_score\": null, \"_source\": { \"username\": \"test_user\", \"language\": \"en\", \"age\": 32, \"height\": \"157\" }, \"sort\": [ 1637620268000 ] } ... ] } } } */ Accessing Elasticsearch Client \u00b6 If ever needed you can also access the client directly import es from \"Utils/elasticsearch\" ; const client = es (). getClient (); await client . index ({ index : \"game-of-thrones\" , body : { character : \"Ned Stark\" , quote : \"Winter is coming.\" , }, }); Available methods \u00b6 es.setConnection \u00b6 This will set the current connection to either aws or default . import es from \"Utils/elasticsearch\" ; es (). setConnection ( \"aws\" ); es.createIndices \u00b6 This will create a new index. import es from \"Utils/elasticsearch\" ; await es (). createIndices ( { character : \"Tyrion Lannister\" , quote : \"A mind needs books like a sword needs a whetstone.\" , }, \"game-of-thrones\" ); es.deleteIndices \u00b6 This will delete one or more indices. For more options, refer here import es from \"Utils/elasticsearch\" ; await es (). deleteIndices ([ \"game-of-thrones\" , \"twitter\" , \"store\" ]); // More options await es (). deleteIndices ( \"game-of-thrones\" , { ignore_unavailable : true , timeout : \"2000\" , }); es.existIndices \u00b6 This will check if an index or indices exists. For more options, refer here import es from \"Utils/elasticsearch\" ; await es (). existIndices ( \"game-of-thrones\" ); // More options await es (). existIndices ( \"game-of-thrones\" , { id : \"1\" , }); es.putMapping \u00b6 This will add new fields to an existing data stream or index. Warning Due to deprecation of type from Elasticsearch 7.0.0, use es.getClient() directly. For more info, refer here import es from \"Utils/elasticsearch\" ; await es (). putMapping ( \"twitter\" , \"user\" , { name : { type : \"text\" }, user_name : { type : \"keyword\" }, email : { type : \"keyword\" }, }); es.get \u00b6 This will retrieve the specified JSON document from an index using the document ID. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). get ( \"0\" ); /** { \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"0\", \"_version\":1, \"_seq_no\":0, \"_primary_term\":1, \"found\":true, \"_source\":{ \"@timestamp\":\"2099-11-15T14:12:12\", \"http\":{ \"request\":{ \"method\":\"get\" }, \"response\":{ \"status_code\":200, \"bytes\":1070000 }, \"version\":\"1.1\" }, \"source\":{ \"ip\":\"127.0.0.1\" }, \"message\":\"GET /search HTTP/1.1 200 1070000\", \"user\":{ \"id\":\"kimchy\" } } } */ es.indexOrCreateById / es.create \u00b6 This will add a JSON document to the specified data stream or index and makes it searchable. If the target is an index and the document already exists, the request updates the document and increments its version, else it is created. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). create ( \"1\" , { character : \"Tyrion Lannister\" , quote : \"A mind needs books like a sword needs a whetstone.\" , }); // Third parameter is to refresh or not await es ({ index : \"game-of-thrones\" }). indexOrCreateById ( { id : \"1\" , character : \"Tyrion Lannister\" , quote : \"A mind needs books like a sword needs a whetstone.\" , }, true ); /** { \"_shards\":{ \"total\":2, \"failed\":0, \"successful\":2 }, \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"W0tpsmIBdwcYyG50zbta\", \"_version\":1, \"_seq_no\":0, \"_primary_term\":1, \"result\":\"created\" } */ es.bulkIndex \u00b6 This will perform multiple indexing or delete operations in a single API call. This reduces overhead and can greatly increase indexing speed. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). bulkIndex ([ { profile_id : \"1\" , text : \"If I fall, don't bring me back.\" , user : \"jon\" , date : new Date (), }, { profile_id : \"2\" , text : \"Winter is coming\" , user : \"ned\" , date : new Date (), }, ]); /** { \"took\":30, \"errors\":false, \"items\":[ { \"index\":{ \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"1\", \"_version\":1, \"result\":\"created\", \"_shards\":{ \"total\":4, \"successful\":2, \"failed\":0 }, \"status\":201, \"_seq_no\":0, \"_primary_term\":1 } } ] } */ es.create \u00b6 This adds a JSON document to the specified data stream or index and makes it searchable. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). create ( \"1\" , { text : \"If I fall, don't bring me back.\" , user : \"jon\" , date : new Date (), }); /** { \"_shards\":{ \"total\":2, \"failed\":0, \"successful\":2 }, \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"1\", \"_version\":1, \"_seq_no\":0, \"_primary_term\":1, \"result\":\"created\" } */","title":"Full-Text Search"},{"location":"advance/full-text-search/#full-text-search","text":"Lesgo! is pre-configured with AWS Elasticsearch for full-text search.","title":"Full-Text Search"},{"location":"advance/full-text-search/#configuration","text":"The elasticsearch configuration for your application is located at src/config/elasticsearch.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # Elasticsearch index name to use ES_INDEX = \"\" # Elasticsaerch mapping type # Empty this line if you are using Elasticsearch \u2264 6 ES_TYPE = \"_doc\" # Elasticsearch node URL ES_NODE = \"\" # Elasticsearch region name ES_REGION = \"\"","title":"Configuration"},{"location":"advance/full-text-search/#basic-usage","text":"To run a basic query, you may use the search method on the Utils/es : import es from \"Utils/elasticsearch\" ; const response = await es (). search ({ query : { match : { quote : \"winter\" , }, }, }); /** { \"body\": { \"took\": 22, \"timed_out\": false, \"_shards\": { \"total\": 6, \"successful\": 6, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 10, \"max_score\": null, \"hits\": [ { \"_index\": \"test_search_20210628\", \"_type\": \"profiles\", \"_id\": \"3692613\", \"_score\": null, \"_source\": { \"username\": \"test_user\", \"language\": \"en\", \"age\": 32, \"height\": \"157\" }, \"sort\": [ 1637620268000 ] } ... ] } } } */","title":"Basic Usage"},{"location":"advance/full-text-search/#advanced-query","text":"import es from \"Utils/elasticsearch\" ; const response = await es (). search ({ from : 0 , size : 4 , query : { bool : { must : [ { match : { account_type : 2 , }, }, ], must_not : { terms : { account_id : [ 3627950 ], }, }, filter : [ { geo_distance : { distance : \"50mi\" , distance_type : \"arc\" , location : { lat : 37.7749295 , lon : - 122.4194155 , }, }, }, ], }, }, sort : [ { last_activity_dt : { order : \"desc\" , }, }, ], }); /** { \"body\": { \"took\": 22, \"timed_out\": false, \"_shards\": { \"total\": 6, \"successful\": 6, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 10, \"max_score\": null, \"hits\": [ { \"_index\": \"test_search_20210628\", \"_type\": \"profiles\", \"_id\": \"3692613\", \"_score\": null, \"_source\": { \"username\": \"test_user\", \"language\": \"en\", \"age\": 32, \"height\": \"157\" }, \"sort\": [ 1637620268000 ] } ... ] } } } */","title":"Advanced Query"},{"location":"advance/full-text-search/#accessing-elasticsearch-client","text":"If ever needed you can also access the client directly import es from \"Utils/elasticsearch\" ; const client = es (). getClient (); await client . index ({ index : \"game-of-thrones\" , body : { character : \"Ned Stark\" , quote : \"Winter is coming.\" , }, });","title":"Accessing Elasticsearch Client"},{"location":"advance/full-text-search/#available-methods","text":"","title":"Available methods"},{"location":"advance/full-text-search/#essetconnection","text":"This will set the current connection to either aws or default . import es from \"Utils/elasticsearch\" ; es (). setConnection ( \"aws\" );","title":"es.setConnection"},{"location":"advance/full-text-search/#escreateindices","text":"This will create a new index. import es from \"Utils/elasticsearch\" ; await es (). createIndices ( { character : \"Tyrion Lannister\" , quote : \"A mind needs books like a sword needs a whetstone.\" , }, \"game-of-thrones\" );","title":"es.createIndices"},{"location":"advance/full-text-search/#esdeleteindices","text":"This will delete one or more indices. For more options, refer here import es from \"Utils/elasticsearch\" ; await es (). deleteIndices ([ \"game-of-thrones\" , \"twitter\" , \"store\" ]); // More options await es (). deleteIndices ( \"game-of-thrones\" , { ignore_unavailable : true , timeout : \"2000\" , });","title":"es.deleteIndices"},{"location":"advance/full-text-search/#esexistindices","text":"This will check if an index or indices exists. For more options, refer here import es from \"Utils/elasticsearch\" ; await es (). existIndices ( \"game-of-thrones\" ); // More options await es (). existIndices ( \"game-of-thrones\" , { id : \"1\" , });","title":"es.existIndices"},{"location":"advance/full-text-search/#esputmapping","text":"This will add new fields to an existing data stream or index. Warning Due to deprecation of type from Elasticsearch 7.0.0, use es.getClient() directly. For more info, refer here import es from \"Utils/elasticsearch\" ; await es (). putMapping ( \"twitter\" , \"user\" , { name : { type : \"text\" }, user_name : { type : \"keyword\" }, email : { type : \"keyword\" }, });","title":"es.putMapping"},{"location":"advance/full-text-search/#esget","text":"This will retrieve the specified JSON document from an index using the document ID. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). get ( \"0\" ); /** { \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"0\", \"_version\":1, \"_seq_no\":0, \"_primary_term\":1, \"found\":true, \"_source\":{ \"@timestamp\":\"2099-11-15T14:12:12\", \"http\":{ \"request\":{ \"method\":\"get\" }, \"response\":{ \"status_code\":200, \"bytes\":1070000 }, \"version\":\"1.1\" }, \"source\":{ \"ip\":\"127.0.0.1\" }, \"message\":\"GET /search HTTP/1.1 200 1070000\", \"user\":{ \"id\":\"kimchy\" } } } */","title":"es.get"},{"location":"advance/full-text-search/#esindexorcreatebyid-escreate","text":"This will add a JSON document to the specified data stream or index and makes it searchable. If the target is an index and the document already exists, the request updates the document and increments its version, else it is created. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). create ( \"1\" , { character : \"Tyrion Lannister\" , quote : \"A mind needs books like a sword needs a whetstone.\" , }); // Third parameter is to refresh or not await es ({ index : \"game-of-thrones\" }). indexOrCreateById ( { id : \"1\" , character : \"Tyrion Lannister\" , quote : \"A mind needs books like a sword needs a whetstone.\" , }, true ); /** { \"_shards\":{ \"total\":2, \"failed\":0, \"successful\":2 }, \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"W0tpsmIBdwcYyG50zbta\", \"_version\":1, \"_seq_no\":0, \"_primary_term\":1, \"result\":\"created\" } */","title":"es.indexOrCreateById / es.create"},{"location":"advance/full-text-search/#esbulkindex","text":"This will perform multiple indexing or delete operations in a single API call. This reduces overhead and can greatly increase indexing speed. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). bulkIndex ([ { profile_id : \"1\" , text : \"If I fall, don't bring me back.\" , user : \"jon\" , date : new Date (), }, { profile_id : \"2\" , text : \"Winter is coming\" , user : \"ned\" , date : new Date (), }, ]); /** { \"took\":30, \"errors\":false, \"items\":[ { \"index\":{ \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"1\", \"_version\":1, \"result\":\"created\", \"_shards\":{ \"total\":4, \"successful\":2, \"failed\":0 }, \"status\":201, \"_seq_no\":0, \"_primary_term\":1 } } ] } */","title":"es.bulkIndex"},{"location":"advance/full-text-search/#escreate","text":"This adds a JSON document to the specified data stream or index and makes it searchable. import es from \"Utils/elasticsearch\" ; await es ({ index : \"game-of-thrones\" }). create ( \"1\" , { text : \"If I fall, don't bring me back.\" , user : \"jon\" , date : new Date (), }); /** { \"_shards\":{ \"total\":2, \"failed\":0, \"successful\":2 }, \"_index\":\"game-of-thrones\", \"_type\":\"_doc\", \"_id\":\"1\", \"_version\":1, \"_seq_no\":0, \"_primary_term\":1, \"result\":\"created\" } */","title":"es.create"},{"location":"advance/helpers/","text":"Helpers \u00b6 Lesgo! comes in-built with various helper functions available within the Utils/ namespace. Crypto \u00b6 Utils/crypto Cryptographic functions using the Crypto npm library. Hash \u00b6 One way hashing of data using SHA-256. import { hash } from \"Utils/crypto\" ; const hashedString = hash ( \"some data to hash\" ); // 6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50 MD5 Hash \u00b6 One way hashing of data using the faster MD5. import { hashMD5 } from \"Utils/crypto\" ; const hashedMD5String = hashMD5 ( \"some data to hash\" ); // 527d738baba016840c3a33f2790845dd Warning While hashMD5 is fast, it is not at all recommended as it is considered a weak 1-iteration hash with no salt. Encrypt \u00b6 2-way encryption with auto-generated iv and cipher. import { encrypt } from \"Utils/crypto\" ; const encryptedStr = encrypt ( \"some string to be encrypted that can be decrypted\" ); // Decrypt \u00b6 Decrypting a previously encrypted data. import { decrypt } from \"Utils/crypto\" ; const decryptedStr = decrypt ( \"some-encrypted-string\" ); // Generate Uid \u00b6 Utils/generateUid Generates random string with an optional prefix and suffix using the Nanoid npm library. Useful for generating unique id. import generateUid from \"Utils/generateUid\" ; const uid = generateUid ()); // 098f6bcd4621d373cade4 const prefixUid = generateUid ({ prefix : \"somePrefix\" })); // somePrefix-621d4bc3cade7d4098f63 const uidSuffix = generateUid ({ suffix : \"someSuffix\" })); // 7d6af6c3cde214093d4b8-someSuffix const uidLimited = generateUid ({ length : 36 })); // ce214094b8daf683d4b7d63ccde21403dd93 Email Format Validator \u00b6 Utils/isEmail Validates for a valid email format. import isEmail from \"Utils/isEmail\" ; isEmail ( \"john@doe.com\" )); // true isEmail ( \"some string\" )); // false Decimal Number Validator \u00b6 Utils/isDecimal Validates for a valid decimal number in any format such as ##.## . import isDecimal from \"Utils/isDecimal\" ; isDecimal ( 5.4 ); // true isDecimal ( 5 ); // false Empty Value Validator \u00b6 Utils/isEmpty Validates if a value is either an undefined , or null , or empty string, or an empty array, or an object without keys. import isEmpty from \"Utils/isEmpty\" ; isEmpty ( undefined ); isEmpty ( null ); isEmpty ({}); isEmpty ([]); isEmpty ( \"\" ); // true isEmpty ( \"test\" ); isEmpty ( 0 ); // false Field Validator \u00b6 Utils/validateFields Validates parameters received to ensure the data is of the right type and exists. import validateFields from \"Utils/validateFields\" ; const validFields = [ { key : \"someString\" , type : \"string\" , required : true }, { key : \"someObject\" , type : \"object\" , required : true }, { key : \"someNumber\" , type : \"number\" , required : true }, { key : \"someDecimal\" , type : \"decimal\" , required : true }, { key : \"someEmail\" , type : \"email\" , required : true }, { key : \"someArray\" , type : \"array\" , required : true }, { key : \"someEnum\" , type : \"enum\" , enumValues : [ \"abc\" , \"def\" , \"xyz\" ], required : true , }, ]; const toValidate1 = { someString : \"The cat\" , someObject : { objKey1 : \"one\" , objKey2 : \"two\" , }, someNumber : 123 , someDecimal : 0.123 , someEmail : \"email@mail.com\" , someArray : [ \"aaa\" , \"bbb\" , \"ccc\" ], someEnum : \"def\" , }; const validated = validateFields ( toValidate1 , validFields )); /** { someString: \"The cat\", someObject: { objKey1: \"one\", objKey2: \"two\", }, someNumber: 123, someDecimal: 0.123, someEmail: \"email@mail.com\", someArray: [\"aaa\", \"bbb\", \"ccc\"], someEnum: \"def\", } */ The example above will pass and return with the exact validated fields in toValidate1 . The next example will throw an Error. const toValidate2 = { ... toValidate1 , someString : 123 , } const validated = validateFields ( toValidate2 , validFields )); /** new LesgoException( `Invalid type for 'someString', expecting 'string'`, `${FILE}::INVALID_TYPE_NAME` ) */ Prep Insert SQL Parameter \u00b6 Utils/prepSQLInsertParams Takes in data and returns a nicely formatted response to be used for Utils/db.insert() . prepSQLInsertParams ( params : Object , // data to insert to db (matching key to db column) columns : Object // valid db column names ) : { insertColumns , // comma-separated db column field names insertValues , // comma-separated field values in prepared statement form i.e; :username, :id, etc insertFields // data object to insert }; Usage import prepSQLInsertParams from \"Utils/prepSQLInsertParams\" ; const params = { username : \"John\" , email : \"john.doe@gmail.com\" , }; const validFields = [ { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; const { insertColumns , insertValues , insertFields } = prepSQLInsertParams ( params , validFields ); See usage with Utils/db.insert() . Prep Update SQL Parameter \u00b6 Utils/prepSQLUpdateParams Takes in data and returns a nicely formatted response to be used for Utils/db.update() . prepSQLUpdateParams ( params : Object , // data to update to db (matching key to db column) columns : Object // valid db column names ) : { updateColumnValues , // comma-separated column=:value pair wherePrimaryKey , // primary key (based on default table.id) updateFields // data object to update }; Usage import prepSQLUpdateParams from \"Utils/prepSQLUpdateParams\" ; const params = { id : 1 , username : \"John\" , email : \"john.doe@gmail.com\" , }; const validFields = [ { key : \"id\" , type : \"number\" , required : true }, { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; const { updateColumnValues , wherePrimaryKey , updateFields } = prepSQLUpdateParams ( params , validFields ); See usage with Utils/db.update() .","title":"Helpers"},{"location":"advance/helpers/#helpers","text":"Lesgo! comes in-built with various helper functions available within the Utils/ namespace.","title":"Helpers"},{"location":"advance/helpers/#crypto","text":"Utils/crypto Cryptographic functions using the Crypto npm library.","title":"Crypto"},{"location":"advance/helpers/#hash","text":"One way hashing of data using SHA-256. import { hash } from \"Utils/crypto\" ; const hashedString = hash ( \"some data to hash\" ); // 6a2da20943931e9834fc12cfe5bb47bbd9ae43489a30726962b576f4e3993e50","title":"Hash"},{"location":"advance/helpers/#md5-hash","text":"One way hashing of data using the faster MD5. import { hashMD5 } from \"Utils/crypto\" ; const hashedMD5String = hashMD5 ( \"some data to hash\" ); // 527d738baba016840c3a33f2790845dd Warning While hashMD5 is fast, it is not at all recommended as it is considered a weak 1-iteration hash with no salt.","title":"MD5 Hash"},{"location":"advance/helpers/#encrypt","text":"2-way encryption with auto-generated iv and cipher. import { encrypt } from \"Utils/crypto\" ; const encryptedStr = encrypt ( \"some string to be encrypted that can be decrypted\" ); //","title":"Encrypt"},{"location":"advance/helpers/#decrypt","text":"Decrypting a previously encrypted data. import { decrypt } from \"Utils/crypto\" ; const decryptedStr = decrypt ( \"some-encrypted-string\" ); //","title":"Decrypt"},{"location":"advance/helpers/#generate-uid","text":"Utils/generateUid Generates random string with an optional prefix and suffix using the Nanoid npm library. Useful for generating unique id. import generateUid from \"Utils/generateUid\" ; const uid = generateUid ()); // 098f6bcd4621d373cade4 const prefixUid = generateUid ({ prefix : \"somePrefix\" })); // somePrefix-621d4bc3cade7d4098f63 const uidSuffix = generateUid ({ suffix : \"someSuffix\" })); // 7d6af6c3cde214093d4b8-someSuffix const uidLimited = generateUid ({ length : 36 })); // ce214094b8daf683d4b7d63ccde21403dd93","title":"Generate Uid"},{"location":"advance/helpers/#email-format-validator","text":"Utils/isEmail Validates for a valid email format. import isEmail from \"Utils/isEmail\" ; isEmail ( \"john@doe.com\" )); // true isEmail ( \"some string\" )); // false","title":"Email Format Validator"},{"location":"advance/helpers/#decimal-number-validator","text":"Utils/isDecimal Validates for a valid decimal number in any format such as ##.## . import isDecimal from \"Utils/isDecimal\" ; isDecimal ( 5.4 ); // true isDecimal ( 5 ); // false","title":"Decimal Number Validator"},{"location":"advance/helpers/#empty-value-validator","text":"Utils/isEmpty Validates if a value is either an undefined , or null , or empty string, or an empty array, or an object without keys. import isEmpty from \"Utils/isEmpty\" ; isEmpty ( undefined ); isEmpty ( null ); isEmpty ({}); isEmpty ([]); isEmpty ( \"\" ); // true isEmpty ( \"test\" ); isEmpty ( 0 ); // false","title":"Empty Value Validator"},{"location":"advance/helpers/#field-validator","text":"Utils/validateFields Validates parameters received to ensure the data is of the right type and exists. import validateFields from \"Utils/validateFields\" ; const validFields = [ { key : \"someString\" , type : \"string\" , required : true }, { key : \"someObject\" , type : \"object\" , required : true }, { key : \"someNumber\" , type : \"number\" , required : true }, { key : \"someDecimal\" , type : \"decimal\" , required : true }, { key : \"someEmail\" , type : \"email\" , required : true }, { key : \"someArray\" , type : \"array\" , required : true }, { key : \"someEnum\" , type : \"enum\" , enumValues : [ \"abc\" , \"def\" , \"xyz\" ], required : true , }, ]; const toValidate1 = { someString : \"The cat\" , someObject : { objKey1 : \"one\" , objKey2 : \"two\" , }, someNumber : 123 , someDecimal : 0.123 , someEmail : \"email@mail.com\" , someArray : [ \"aaa\" , \"bbb\" , \"ccc\" ], someEnum : \"def\" , }; const validated = validateFields ( toValidate1 , validFields )); /** { someString: \"The cat\", someObject: { objKey1: \"one\", objKey2: \"two\", }, someNumber: 123, someDecimal: 0.123, someEmail: \"email@mail.com\", someArray: [\"aaa\", \"bbb\", \"ccc\"], someEnum: \"def\", } */ The example above will pass and return with the exact validated fields in toValidate1 . The next example will throw an Error. const toValidate2 = { ... toValidate1 , someString : 123 , } const validated = validateFields ( toValidate2 , validFields )); /** new LesgoException( `Invalid type for 'someString', expecting 'string'`, `${FILE}::INVALID_TYPE_NAME` ) */","title":"Field Validator"},{"location":"advance/helpers/#prep-insert-sql-parameter","text":"Utils/prepSQLInsertParams Takes in data and returns a nicely formatted response to be used for Utils/db.insert() . prepSQLInsertParams ( params : Object , // data to insert to db (matching key to db column) columns : Object // valid db column names ) : { insertColumns , // comma-separated db column field names insertValues , // comma-separated field values in prepared statement form i.e; :username, :id, etc insertFields // data object to insert }; Usage import prepSQLInsertParams from \"Utils/prepSQLInsertParams\" ; const params = { username : \"John\" , email : \"john.doe@gmail.com\" , }; const validFields = [ { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; const { insertColumns , insertValues , insertFields } = prepSQLInsertParams ( params , validFields ); See usage with Utils/db.insert() .","title":"Prep Insert SQL Parameter"},{"location":"advance/helpers/#prep-update-sql-parameter","text":"Utils/prepSQLUpdateParams Takes in data and returns a nicely formatted response to be used for Utils/db.update() . prepSQLUpdateParams ( params : Object , // data to update to db (matching key to db column) columns : Object // valid db column names ) : { updateColumnValues , // comma-separated column=:value pair wherePrimaryKey , // primary key (based on default table.id) updateFields // data object to update }; Usage import prepSQLUpdateParams from \"Utils/prepSQLUpdateParams\" ; const params = { id : 1 , username : \"John\" , email : \"john.doe@gmail.com\" , }; const validFields = [ { key : \"id\" , type : \"number\" , required : true }, { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; const { updateColumnValues , wherePrimaryKey , updateFields } = prepSQLUpdateParams ( params , validFields ); See usage with Utils/db.update() .","title":"Prep Update SQL Parameter"},{"location":"advance/object-store/","text":"Object Store \u00b6 Lesgo! is pre-configured with AWS S3 for object storage. Configuration \u00b6 The S3 configuration for your application is located at src/config/aws.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # S3 Access Key ID AWS_S3_OPTIONS_ACCESS_KEY_ID = \"\" # S3 Secret Access Key AWS_S3_OPTIONS_SECRET_ACCESS_KEY = \"\" # S3 region name AWS_S3_OPTIONS_REGION = \"\" Fetch Object \u00b6 The getObject() function will fetch the object from the Bucket. import { getObject } from 'Utils/objectStore' ; // Returns a buffered object response. See AWS for more information const objectFile = await getObject ( 'Key' , 'Bucket' ); S3 Bucket Permissions Policy \u00b6 To fetch/put objects to an exisitng S3 bucket, be sure to set up an IAM user with the correct permissions as well as updating the S3 bucket policy. You may override the config by updating these in the environment file. # Set IAM access key with S3 access AWS_S3_OPTIONS_ACCESS_KEY_ID = # Set IAM secret key AWS_S3_OPTIONS_SECRET_ACCESS_KEY = # Set S3 region to connect to AWS_S3_OPTIONS_REGION =","title":"Object Store"},{"location":"advance/object-store/#object-store","text":"Lesgo! is pre-configured with AWS S3 for object storage.","title":"Object Store"},{"location":"advance/object-store/#configuration","text":"The S3 configuration for your application is located at src/config/aws.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # S3 Access Key ID AWS_S3_OPTIONS_ACCESS_KEY_ID = \"\" # S3 Secret Access Key AWS_S3_OPTIONS_SECRET_ACCESS_KEY = \"\" # S3 region name AWS_S3_OPTIONS_REGION = \"\"","title":"Configuration"},{"location":"advance/object-store/#fetch-object","text":"The getObject() function will fetch the object from the Bucket. import { getObject } from 'Utils/objectStore' ; // Returns a buffered object response. See AWS for more information const objectFile = await getObject ( 'Key' , 'Bucket' );","title":"Fetch Object"},{"location":"advance/object-store/#s3-bucket-permissions-policy","text":"To fetch/put objects to an exisitng S3 bucket, be sure to set up an IAM user with the correct permissions as well as updating the S3 bucket policy. You may override the config by updating these in the environment file. # Set IAM access key with S3 access AWS_S3_OPTIONS_ACCESS_KEY_ID = # Set IAM secret key AWS_S3_OPTIONS_SECRET_ACCESS_KEY = # Set S3 region to connect to AWS_S3_OPTIONS_REGION =","title":"S3 Bucket Permissions Policy"},{"location":"advance/queues/","text":"Queues \u00b6 Lesgo! is pre-configured with AWS SQS for queues. Configuration \u00b6 The SQS configuration for your application is located at src/config/aws.js . Or copy this file to that path, a sampleQueue is created for you as a sample. You may also simply update the respective environment files in config/environments/* as such: # SQS Access Key ID AWS_SQS_OPTIONS_ACCESS_KEY_ID = \"\" # SQS Secret Access Key AWS_SQS_OPTIONS_SECRET_ACCESS_KEY = \"\" # SQS region name AWS_SQS_OPTIONS_REGION = \"\" Queue Dispatch Event \u00b6 The Utils/dispatch function will dispatch a message payload to the queue. Usage \u00b6 This example usage will send a message to the pre-defined PingQueue. import { dispatch } from \"Utils/queue\" ; const payload = { someData : \"someValue\" , }; return await dispatch ( payload , \"pingQueue\" ); Consuming Dispatached Queued Messages \u00b6 Messages sent to SQS can automatically trigger and be executed by a Lambda Function. This can be configured to an event lambda function within the config/functions . config/functions/dequeue.yml dequeue : handler : ${self:custom.path.app}/handlers/dequeue.handler description : Receives message from SQS for actual business logic execution timeout : 15 events : - sqs : arn:aws:sqs:${self:provider.region}:${env:AWS_ACCOUNT_ID}:${self:provider.stackName}-dequeue Batch Processing Queued Messages \u00b6 Messages can also be fetched and executed in batches. ... Processing Queued Messages with FIFO \u00b6 Messages can also be consumed in FIFO. ...","title":"Queues"},{"location":"advance/queues/#queues","text":"Lesgo! is pre-configured with AWS SQS for queues.","title":"Queues"},{"location":"advance/queues/#configuration","text":"The SQS configuration for your application is located at src/config/aws.js . Or copy this file to that path, a sampleQueue is created for you as a sample. You may also simply update the respective environment files in config/environments/* as such: # SQS Access Key ID AWS_SQS_OPTIONS_ACCESS_KEY_ID = \"\" # SQS Secret Access Key AWS_SQS_OPTIONS_SECRET_ACCESS_KEY = \"\" # SQS region name AWS_SQS_OPTIONS_REGION = \"\"","title":"Configuration"},{"location":"advance/queues/#queue-dispatch-event","text":"The Utils/dispatch function will dispatch a message payload to the queue.","title":"Queue Dispatch Event"},{"location":"advance/queues/#usage","text":"This example usage will send a message to the pre-defined PingQueue. import { dispatch } from \"Utils/queue\" ; const payload = { someData : \"someValue\" , }; return await dispatch ( payload , \"pingQueue\" );","title":"Usage"},{"location":"advance/queues/#consuming-dispatached-queued-messages","text":"Messages sent to SQS can automatically trigger and be executed by a Lambda Function. This can be configured to an event lambda function within the config/functions . config/functions/dequeue.yml dequeue : handler : ${self:custom.path.app}/handlers/dequeue.handler description : Receives message from SQS for actual business logic execution timeout : 15 events : - sqs : arn:aws:sqs:${self:provider.region}:${env:AWS_ACCOUNT_ID}:${self:provider.stackName}-dequeue","title":"Consuming Dispatached Queued Messages"},{"location":"advance/queues/#batch-processing-queued-messages","text":"Messages can also be fetched and executed in batches. ...","title":"Batch Processing Queued Messages"},{"location":"advance/queues/#processing-queued-messages-with-fifo","text":"Messages can also be consumed in FIFO. ...","title":"Processing Queued Messages with FIFO"},{"location":"advance/task-scheduling/","text":"Task Scheduling \u00b6 Lesgo! utilizes the CloudWatch Scheduled Event type to schedule events. This is the equivalent as you would configured a Cron entry on an application server. Defining Schedules \u00b6 Define a scheduled event by first inserting a function with the event:schedule type in your serverless function yaml. functions : - pingScheduledEvent : handler : src/app/handlers/scheduledEvent.handler description : Lambda event triggered from Scheduled Cloudwatch Event events : - schedule : name : scheduledEvent description : Trigger lambda function every 5 minute rate : rate(5 minutes) enabled : true The above configuration will execute a CloudWatch Scheduled Event every 5 mins. This scheduled event will execute the handler.","title":"Task Scheduling"},{"location":"advance/task-scheduling/#task-scheduling","text":"Lesgo! utilizes the CloudWatch Scheduled Event type to schedule events. This is the equivalent as you would configured a Cron entry on an application server.","title":"Task Scheduling"},{"location":"advance/task-scheduling/#defining-schedules","text":"Define a scheduled event by first inserting a function with the event:schedule type in your serverless function yaml. functions : - pingScheduledEvent : handler : src/app/handlers/scheduledEvent.handler description : Lambda event triggered from Scheduled Cloudwatch Event events : - schedule : name : scheduledEvent description : Trigger lambda function every 5 minute rate : rate(5 minutes) enabled : true The above configuration will execute a CloudWatch Scheduled Event every 5 mins. This scheduled event will execute the handler.","title":"Defining Schedules"},{"location":"advance/typescript/","text":"Typescript \u00b6 Lesgo! can be integrated with a TS code-base. Installation \u00b6 To enable typescript for Lesgo!, follow the steps below. Install @types package npm install -D @types/lesgo Rename jsconfig.json to tsconfig.json and verify contents to have these: { \"compilerOptions\" : { ... \"paths\" : { ... \"Exceptions/*\" : [ ... \"node_modules/@types/lesgo/exceptions/*\" ], \"Middlewares/*\" : [ ... \"node_modules/@types/lesgo/middlewares/*\" ], \"Services/*\" : [ ... \"node_modules/@types/lesgo/services/*\" ], \"Utils/*\" : [ ... \"node_modules/@types/lesgo/utils/*\" ] } } }","title":"Typescript"},{"location":"advance/typescript/#typescript","text":"Lesgo! can be integrated with a TS code-base.","title":"Typescript"},{"location":"advance/typescript/#installation","text":"To enable typescript for Lesgo!, follow the steps below. Install @types package npm install -D @types/lesgo Rename jsconfig.json to tsconfig.json and verify contents to have these: { \"compilerOptions\" : { ... \"paths\" : { ... \"Exceptions/*\" : [ ... \"node_modules/@types/lesgo/exceptions/*\" ], \"Middlewares/*\" : [ ... \"node_modules/@types/lesgo/middlewares/*\" ], \"Services/*\" : [ ... \"node_modules/@types/lesgo/services/*\" ], \"Utils/*\" : [ ... \"node_modules/@types/lesgo/utils/*\" ] } } }","title":"Installation"},{"location":"advance/unit-tests/","text":"Unit Tests \u00b6 Lesgo! uses Jest testing framework for unit testing. All test files exist in the tests/ directory. Run Test \u00b6 This command will execute the unit testing. npm test Run Coverage Report \u00b6 This command will execute the unit testing and generate a code coverage report. npm run coverage View the generated html report in coverage/index.html . Test environment \u00b6 Declare test environment configurations as NODE variables in tests/setupTest.js .","title":"Unit Tests"},{"location":"advance/unit-tests/#unit-tests","text":"Lesgo! uses Jest testing framework for unit testing. All test files exist in the tests/ directory.","title":"Unit Tests"},{"location":"advance/unit-tests/#run-test","text":"This command will execute the unit testing. npm test","title":"Run Test"},{"location":"advance/unit-tests/#run-coverage-report","text":"This command will execute the unit testing and generate a code coverage report. npm run coverage View the generated html report in coverage/index.html .","title":"Run Coverage Report"},{"location":"advance/unit-tests/#test-environment","text":"Declare test environment configurations as NODE variables in tests/setupTest.js .","title":"Test environment"},{"location":"basics/error-handling/","text":"Error Handling \u00b6 It is recommended to always throw an Error class as an exception instead of returning just an error message. You may create your own Error Class within the src/exceptions/ directory. import MediaException from 'Exceptions/MediaException' ; ... try { return validateFields ( params , validFields ); } catch ( err ) { throw new MediaException ( err . message , `Core/medias/getMedia::FIELD_VALIDATION_EXCEPTION` , 400 , { params , err } ); } Custom Error Classes \u00b6 You can define your own Error Classes as required. Refer to the existing src/exceptions/ErrorException.js class. Sentry \u00b6 Lesgo! is pre-configured to work with sentry out of the box Configuration \u00b6 The sentry configuration for your application is located at src/config/sentry.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # Whether to enable sentry or not SENTRY_ENABLED = \"true\" # Where to send events SENTRY_DSN = \"https://public@sentry.example.com/1\" # Minimal level for error reporting. Ref: https://github.com/winstonjs/winston#logging SENTRY_LEVEL = \"error\" # Track release version and for sourcemaps reference SENTRY_RELEASE = \"sls-my-project-maste\" Initialization \u00b6 Call this as early as possible on any of your lambdas. A suggestion would be to put this inside of a middleware import connectSentry from \"Utils/sentry\" ; connectSentry ();","title":"Error Handling"},{"location":"basics/error-handling/#error-handling","text":"It is recommended to always throw an Error class as an exception instead of returning just an error message. You may create your own Error Class within the src/exceptions/ directory. import MediaException from 'Exceptions/MediaException' ; ... try { return validateFields ( params , validFields ); } catch ( err ) { throw new MediaException ( err . message , `Core/medias/getMedia::FIELD_VALIDATION_EXCEPTION` , 400 , { params , err } ); }","title":"Error Handling"},{"location":"basics/error-handling/#custom-error-classes","text":"You can define your own Error Classes as required. Refer to the existing src/exceptions/ErrorException.js class.","title":"Custom Error Classes"},{"location":"basics/error-handling/#sentry","text":"Lesgo! is pre-configured to work with sentry out of the box","title":"Sentry"},{"location":"basics/error-handling/#configuration","text":"The sentry configuration for your application is located at src/config/sentry.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # Whether to enable sentry or not SENTRY_ENABLED = \"true\" # Where to send events SENTRY_DSN = \"https://public@sentry.example.com/1\" # Minimal level for error reporting. Ref: https://github.com/winstonjs/winston#logging SENTRY_LEVEL = \"error\" # Track release version and for sourcemaps reference SENTRY_RELEASE = \"sls-my-project-maste\"","title":"Configuration"},{"location":"basics/error-handling/#initialization","text":"Call this as early as possible on any of your lambdas. A suggestion would be to put this inside of a middleware import connectSentry from \"Utils/sentry\" ; connectSentry ();","title":"Initialization"},{"location":"basics/logging/","text":"Logging \u00b6 Lesgo! is configured with structured logging. Structured logs will appear on the console by default. import logger from \"Utils/logger\" ; logger . log ( \"info\" , \"this is an info log\" ); logger . info ( \"This is an info log\" ); logger . warn ( \"This is a warning log\" ); logger . error ( \"This is an error log\" ); logger . debug ( \"This is a debug log and will only get logged when APP_DEBUG=true\" ); PRO TIP This logger is built for, and works well, with both CloudWatch and DataDog. DataDog will help you monitor your logs, errors, inovations, and alot more in almost real-time with no performance impact! You may also add additional custom metadata as such: logger . info ( \"This is an info log with my own custom metadata\" , { customData1 : \"someData1\" , customData2 : \"someData2\" , });","title":"Logging"},{"location":"basics/logging/#logging","text":"Lesgo! is configured with structured logging. Structured logs will appear on the console by default. import logger from \"Utils/logger\" ; logger . log ( \"info\" , \"this is an info log\" ); logger . info ( \"This is an info log\" ); logger . warn ( \"This is a warning log\" ); logger . error ( \"This is an error log\" ); logger . debug ( \"This is a debug log and will only get logged when APP_DEBUG=true\" ); PRO TIP This logger is built for, and works well, with both CloudWatch and DataDog. DataDog will help you monitor your logs, errors, inovations, and alot more in almost real-time with no performance impact! You may also add additional custom metadata as such: logger . info ( \"This is an info log with my own custom metadata\" , { customData1 : \"someData1\" , customData2 : \"someData2\" , });","title":"Logging"},{"location":"basics/middleware/","text":"Middleware \u00b6 Middlewares can be executed before or after a request, usually handled by the handlers. This will be useful for cases where an action is required prior to reaching the handler, or when an action is required to execute prior to the returning of the response. Middlewares require Middy npm to work. Middlewares should be written in the src/middlewares/ directory. Available Middlewares \u00b6 Lesgo! comes with 3 pre-existing middlewares. You may also import other ready-made middlewares from the Middy repository . Http \u00b6 This middleware normalizes all HTTP requests, handles, and formats success and error responses, and should be used for all HTTP endpoints. Will also provide any or both JSON body and url querystring parameters into a single event.input . This middleware will also populate with event.auth.sub when JWT is used and presented with the Authorization header. Usage import middy from '@middy/core' ; import httpMiddleware from \"Middlewares/httpMiddleware\" ; const originalHandler = event => { return event . input ; }; export const handler = middy ( originalHandler ); handler . use ( httpMiddleware ()); Success Response \u00b6 The successfuly response will be formatted in this way { \"status\" : \"success\" , \"data\" : {}, \"_meta\" : {} } Error Response \u00b6 The successfuly response will be formatted in this way { \"status\" : \"error\" , \"data\" : null , \"error\" : { \"code\" : \"Core/users/getUser::USER_NOT_EXIST\" , \"message\" : \"UserException: User does not exist\" , \"details\" : { \"err\" : { \"name\" : \"UserException\" , \"message\" : \"User not found\" , \"statusCode\" : 404 , \"code\" : \"Core/users/getUser::USER_NOT_EXIST\" , \"extra\" : {} } } }, \"_meta\" : {} } Normalize SQS Message \u00b6 This middleware will normalize records coming from sqs message event. The Records object in the handler.event will be normalized into handler.event.collection . This middleware executes before the handler is called. Usage import middy from '@middy/core' ; import normalizeSQSMessage from \"Middlewares/normalizeSQSMessage\" ; const originalHandler = event => { return event . collection ; }; export const handler = middy ( originalHandler ); handler . use ( normalizeSQSMessage ()); Verify JWT \u00b6 This middleware will verify any JWT passed to the Authorization header of the http request. The decoded JWT can be accesed through handler.event.decodedJwt . If the JWT is verified, handler.event.auth.sub is set to the JWT's sub, else a 403 response will be thrown. Configuration The JWT configuration for your application is located at src/config/jwt.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # SHA256 JWT secret key, used to verify the token passed to \"Authorization\" header JWT_SECRET = \"\" # Leave empty if you don't want the issuer to be validated JWT_ISS_SHOULD_VALIDATE = # Comma-separated list of domains to validate JWT_ISS_DOMAINS = \"\" # Leave empty if you don't want the custom claims to be validated JWT_CUSTOM_CLAIMS_SHOULD_VALIDATE = # List of custom claims to valdiate. # Visit https://auth0.com/docs/tokens/jwt-claims for more info JWT_CUSTOM_CLAIMS_DATA = \"\" Usage import middy from '@middy/core' ; import verifyJwtTokenMiddleware from \"Middlewares/verifyJwtTokenMiddleware\" ; const originalHandler = event => { return event . collection ; }; export const handler = middy ( originalHandler ); handler . use ( verifyJwtTokenMiddleware ()); Custom Middlewares \u00b6 You can write your own custom middleware with Middy .","title":"Middleware"},{"location":"basics/middleware/#middleware","text":"Middlewares can be executed before or after a request, usually handled by the handlers. This will be useful for cases where an action is required prior to reaching the handler, or when an action is required to execute prior to the returning of the response. Middlewares require Middy npm to work. Middlewares should be written in the src/middlewares/ directory.","title":"Middleware"},{"location":"basics/middleware/#available-middlewares","text":"Lesgo! comes with 3 pre-existing middlewares. You may also import other ready-made middlewares from the Middy repository .","title":"Available Middlewares"},{"location":"basics/middleware/#http","text":"This middleware normalizes all HTTP requests, handles, and formats success and error responses, and should be used for all HTTP endpoints. Will also provide any or both JSON body and url querystring parameters into a single event.input . This middleware will also populate with event.auth.sub when JWT is used and presented with the Authorization header. Usage import middy from '@middy/core' ; import httpMiddleware from \"Middlewares/httpMiddleware\" ; const originalHandler = event => { return event . input ; }; export const handler = middy ( originalHandler ); handler . use ( httpMiddleware ());","title":"Http"},{"location":"basics/middleware/#success-response","text":"The successfuly response will be formatted in this way { \"status\" : \"success\" , \"data\" : {}, \"_meta\" : {} }","title":"Success Response"},{"location":"basics/middleware/#error-response","text":"The successfuly response will be formatted in this way { \"status\" : \"error\" , \"data\" : null , \"error\" : { \"code\" : \"Core/users/getUser::USER_NOT_EXIST\" , \"message\" : \"UserException: User does not exist\" , \"details\" : { \"err\" : { \"name\" : \"UserException\" , \"message\" : \"User not found\" , \"statusCode\" : 404 , \"code\" : \"Core/users/getUser::USER_NOT_EXIST\" , \"extra\" : {} } } }, \"_meta\" : {} }","title":"Error Response"},{"location":"basics/middleware/#normalize-sqs-message","text":"This middleware will normalize records coming from sqs message event. The Records object in the handler.event will be normalized into handler.event.collection . This middleware executes before the handler is called. Usage import middy from '@middy/core' ; import normalizeSQSMessage from \"Middlewares/normalizeSQSMessage\" ; const originalHandler = event => { return event . collection ; }; export const handler = middy ( originalHandler ); handler . use ( normalizeSQSMessage ());","title":"Normalize SQS Message"},{"location":"basics/middleware/#verify-jwt","text":"This middleware will verify any JWT passed to the Authorization header of the http request. The decoded JWT can be accesed through handler.event.decodedJwt . If the JWT is verified, handler.event.auth.sub is set to the JWT's sub, else a 403 response will be thrown. Configuration The JWT configuration for your application is located at src/config/jwt.js . Or copy this file to that path. You may also simply update the respective environment files in config/environments/* as such: # SHA256 JWT secret key, used to verify the token passed to \"Authorization\" header JWT_SECRET = \"\" # Leave empty if you don't want the issuer to be validated JWT_ISS_SHOULD_VALIDATE = # Comma-separated list of domains to validate JWT_ISS_DOMAINS = \"\" # Leave empty if you don't want the custom claims to be validated JWT_CUSTOM_CLAIMS_SHOULD_VALIDATE = # List of custom claims to valdiate. # Visit https://auth0.com/docs/tokens/jwt-claims for more info JWT_CUSTOM_CLAIMS_DATA = \"\" Usage import middy from '@middy/core' ; import verifyJwtTokenMiddleware from \"Middlewares/verifyJwtTokenMiddleware\" ; const originalHandler = event => { return event . collection ; }; export const handler = middy ( originalHandler ); handler . use ( verifyJwtTokenMiddleware ());","title":"Verify JWT"},{"location":"basics/middleware/#custom-middlewares","text":"You can write your own custom middleware with Middy .","title":"Custom Middlewares"},{"location":"database/dynamodb/","text":"AWS DynamoDB \u00b6 Fast NoSQL key-value database. Configuration \u00b6 Create a new YAML configuration file dynamodb.yml and place it under config/resources/ directory. # config/resources/dynamodb.yml Resources : settingsTable : Type : AWS::DynamoDB::Table DeletionPolicy : Retain Properties : TableName : ActorsTable AttributeDefinitions : - AttributeName : actorName AttributeType : S - AttributeName : movieName AttributeType : S KeySchema : - AttributeName : actorName KeyType : HASH - AttributeName : movieName KeyType : RANGE BillingMode : PAY_PER_REQUEST Add the YAML file link to serverless.yml under the resources section. # serverless.yml resources : - config/resources/dynamodb.yml Running DynamoDB Queries \u00b6 Retrieving Records \u00b6 dynamodb.query() will return all matching records based on pre-determined primary key, primary and sort key combination, or global secondary index key. dynamodb . query ( tableName : String , // name of the dynamodb table keyConditionExpression : String , // primary or primary with sort or GSI key condition expressionAttributeValues : Object , // key-value pair projectionExpression : String = \"\" // data to return ); Usage import dynamodb from \"Utils/dynamodb\" ; const user = await dynamodb . query ( \"ActorsTable\" , \"actorName = :actorName and movieName = :movieName\" , { \":actorName\" : \"Tom Hanks\" , \":movieName\" : \"Toy Story\" , } ); /** [ { actorName: 'Tom Hanks', movieName: 'Toy Story', }, ... ] */ Retrieving Record Count \u00b6 dynamodb.queryCount() will return the number of query records. dynamodb . queryCount ( tableName : String , // name of the dynamodb table keyConditionExpression : String , // primary or primary with sort or GSI key condition expressionAttributeValues : Object , // key-value pair ); Usage import dynamodb from \"Utils/dynamodb\" ; const count = await dynamodb . queryCount ( \"ActorsTable\" , \"actorName = :actorName\" , { \":actorName\" : \"Tom Hanks\" , } ); // 5 Inserting a Record \u00b6 dynamodb.put() will insert a new record. dynamodb . put ( tableName : String , item : Object }); Usage import dynamodb from \"Utils/dynamodb\" ; const data = await dynamodb . put ( \"ActorTable\" , { actorName : \"Keanue Reaves\" , movieName : \"Speed\" , }); Updating Existing Record \u00b6 dynamodb.update() will update an existing record. dynamodb . update ( tableName : String , key : Object , updateExpression : String , expressionAttributeValues : Object , }); Usage import dynamodb from \"Utils/dynamodb\" ; const data = await dynamodb . update ( \"ActorsTable\" , { actorName : \"Tom Hanks\" , movieName : \"Toy Story\" , }, \"set role = :role\" , { \":role\" : \"Woody\" , } ); Native Client \u00b6 Should you need to execute any other methods not already available, use the exported dynamodb.client to execute any of the available client functions. Example available client query method const resp = await dynamodb . client . query ({ ExpressionAttributeValues : { \":actorName\" : \"Tom Hanks\" , }, KeyConditionExpression : \"actorName = :actorName\" , ProjectionExpression : \"actorName, movieName\" , TableName : \"ActorTable\" , }) . promise (); Refer to the official documentation here .","title":"DynamoDB"},{"location":"database/dynamodb/#aws-dynamodb","text":"Fast NoSQL key-value database.","title":"AWS DynamoDB"},{"location":"database/dynamodb/#configuration","text":"Create a new YAML configuration file dynamodb.yml and place it under config/resources/ directory. # config/resources/dynamodb.yml Resources : settingsTable : Type : AWS::DynamoDB::Table DeletionPolicy : Retain Properties : TableName : ActorsTable AttributeDefinitions : - AttributeName : actorName AttributeType : S - AttributeName : movieName AttributeType : S KeySchema : - AttributeName : actorName KeyType : HASH - AttributeName : movieName KeyType : RANGE BillingMode : PAY_PER_REQUEST Add the YAML file link to serverless.yml under the resources section. # serverless.yml resources : - config/resources/dynamodb.yml","title":"Configuration"},{"location":"database/dynamodb/#running-dynamodb-queries","text":"","title":"Running DynamoDB Queries"},{"location":"database/dynamodb/#retrieving-records","text":"dynamodb.query() will return all matching records based on pre-determined primary key, primary and sort key combination, or global secondary index key. dynamodb . query ( tableName : String , // name of the dynamodb table keyConditionExpression : String , // primary or primary with sort or GSI key condition expressionAttributeValues : Object , // key-value pair projectionExpression : String = \"\" // data to return ); Usage import dynamodb from \"Utils/dynamodb\" ; const user = await dynamodb . query ( \"ActorsTable\" , \"actorName = :actorName and movieName = :movieName\" , { \":actorName\" : \"Tom Hanks\" , \":movieName\" : \"Toy Story\" , } ); /** [ { actorName: 'Tom Hanks', movieName: 'Toy Story', }, ... ] */","title":"Retrieving Records"},{"location":"database/dynamodb/#retrieving-record-count","text":"dynamodb.queryCount() will return the number of query records. dynamodb . queryCount ( tableName : String , // name of the dynamodb table keyConditionExpression : String , // primary or primary with sort or GSI key condition expressionAttributeValues : Object , // key-value pair ); Usage import dynamodb from \"Utils/dynamodb\" ; const count = await dynamodb . queryCount ( \"ActorsTable\" , \"actorName = :actorName\" , { \":actorName\" : \"Tom Hanks\" , } ); // 5","title":"Retrieving Record Count"},{"location":"database/dynamodb/#inserting-a-record","text":"dynamodb.put() will insert a new record. dynamodb . put ( tableName : String , item : Object }); Usage import dynamodb from \"Utils/dynamodb\" ; const data = await dynamodb . put ( \"ActorTable\" , { actorName : \"Keanue Reaves\" , movieName : \"Speed\" , });","title":"Inserting a Record"},{"location":"database/dynamodb/#updating-existing-record","text":"dynamodb.update() will update an existing record. dynamodb . update ( tableName : String , key : Object , updateExpression : String , expressionAttributeValues : Object , }); Usage import dynamodb from \"Utils/dynamodb\" ; const data = await dynamodb . update ( \"ActorsTable\" , { actorName : \"Tom Hanks\" , movieName : \"Toy Story\" , }, \"set role = :role\" , { \":role\" : \"Woody\" , } );","title":"Updating Existing Record"},{"location":"database/dynamodb/#native-client","text":"Should you need to execute any other methods not already available, use the exported dynamodb.client to execute any of the available client functions. Example available client query method const resp = await dynamodb . client . query ({ ExpressionAttributeValues : { \":actorName\" : \"Tom Hanks\" , }, KeyConditionExpression : \"actorName = :actorName\" , ProjectionExpression : \"actorName, movieName\" , TableName : \"ActorTable\" , }) . promise (); Refer to the official documentation here .","title":"Native Client"},{"location":"database/getting-started/","text":"Getting Started \u00b6 As of today, Lesgo! supports the following database services. AWS DynamoDB AWS DynamoDB is highly recommended as it works seamlessly with Lambda, is on-demand, and considered a true serverless database; paid on demand per usage basis. See docs . AWS RDS Aurora Serverless Should you needed a traditional relational database, then AWS RDS Aurora Serverless is the next best choice. Aurora Serverless is auto-scalable and pay only when it is up and running. It also allows you to connect to its Data API; removing the need to manage connection pools 1 and leaving it to the Data API to manage that for you. See docs . AWS RDS Aurora Provisioned Should you need to connect to an existing database that is already setup, AWS RDS Aurora Provisioned is also supported. It is recommedned to connect Lesgo! via RDS Proxy to manage connection pooling 1 . See docs . Connection Pooling is an important factor when considering for connecting to any database engine. This is because Lambda will need to establish a database connection before it can make any queries. As Lambda is scalable, each request will create its own connection, resulting in massive hits to the db connection load. With Data API and RDS Proxy, connection pooling is automatically handled for you with a separate service that is fully managed by AWS. \u21a9 \u21a9","title":"Getting Started"},{"location":"database/getting-started/#getting-started","text":"As of today, Lesgo! supports the following database services. AWS DynamoDB AWS DynamoDB is highly recommended as it works seamlessly with Lambda, is on-demand, and considered a true serverless database; paid on demand per usage basis. See docs . AWS RDS Aurora Serverless Should you needed a traditional relational database, then AWS RDS Aurora Serverless is the next best choice. Aurora Serverless is auto-scalable and pay only when it is up and running. It also allows you to connect to its Data API; removing the need to manage connection pools 1 and leaving it to the Data API to manage that for you. See docs . AWS RDS Aurora Provisioned Should you need to connect to an existing database that is already setup, AWS RDS Aurora Provisioned is also supported. It is recommedned to connect Lesgo! via RDS Proxy to manage connection pooling 1 . See docs . Connection Pooling is an important factor when considering for connecting to any database engine. This is because Lambda will need to establish a database connection before it can make any queries. As Lambda is scalable, each request will create its own connection, resulting in massive hits to the db connection load. With Data API and RDS Proxy, connection pooling is automatically handled for you with a separate service that is fully managed by AWS. \u21a9 \u21a9","title":"Getting Started"},{"location":"database/rds-aurora/","text":"AWS RDS Aurora \u00b6 MySQL and PostgreSQL-compatible relational database built for the cloud. Performance and availability of commercial-grade databases at 1/10th the cost. Configuration \u00b6 The database configuration for your application is located at src/config/db.js . Or copy this file to that path. Aurora Serverless \u00b6 Note As Lesgo! establishes connection to Aurora Serverless via the Data API, prior setup and storing of the credentials on AWS Secret Manager is required. Find out more . For Aurora Serverless via Data API, create a connections.dataApi configuration as shown below. // src/config/db.js export default { default : \"dataApi\" , connections : { dataApi : { secretArn : process . env . DB_SECRET_ARN || \"secretArnDataApi\" , secretCommandArn : process . env . DB_SECRET_COMMAND_ARN || \"secretCommandArnDataApi\" , resourceArn : process . env . DB_RESOURCE_ARN || \"resourceArnDataApi\" , database : process . env . DB_NAME || \"databaseDataApi\" , }, }, }; You may also simply update the respective environment files in config/environments/.env.* as such: # AWS Secret Manager ARN to allow app db user connect to the specified db DB_SECRET_ARN = \"\" # AWS Secret Manager ARN to allow app command db user connect to the specified db # for running \"command\" like functions like database schema migration DB_SECRET_COMMAND_ARN = \"\" # AWS Secret Manager ARN for the Aurora Serverless database cluster DB_RESOURCE_ARN = \"\" # Database name to connect to DB_NAME = \"\" Aurora Provisioned \u00b6 Note As Lesgo! establishes connection to Aurora Provisioned via the RDS Proxy, prior setup of the RDS Proxy is required. Find out more . For Aurora Provisioned via RDS Proxy, create a connections.rdsProxy configuration as shown below. // src/config/db.js export default { default : \"rdsProxy\" , connections : { rdsProxy : { host : process . env . DB_RDS_PROXY_HOST || \"rds-cluster-proxy.proxy-ek9srsfbg2xc.us-west-2.rds.amazonaws.com\" , user : process . env . DB_RDS_PROXY_USER || \"proxyUser\" , password : process . env . DB_RDS_PROXY_PASSWORD || \"proxyPass\" , database : process . env . DB_NAME || \"dbname\" , }, rdsProxyRead : { host : process . env . DB_RDS_PROXY_HOST_READ || process . env . DB_RDS_PROXY_HOST || \"rds-cluster-proxy-read-only.proxy-ek9srsfbg2xc.us-west-2.rds.amazonaws.com\" , user : process . env . DB_RDS_PROXY_USER_READ || process . env . DB_RDS_PROXY_USER || \"proxyUser\" , password : process . env . DB_RDS_PROXY_PASSWORD_READ || process . env . DB_RDS_PROXY_PASSWORD || \"proxyPass\" , database : process . env . DB_NAME || \"dbname\" , }, }, }; You may also simply update the respective environment files in config/environments/env.* as such: # config/environments/.env.* # Domain host of the RDS Proxy DB_RDS_PROXY_HOST = \"\" # Domain host of the RDS Proxy for read-only connection DB_RDS_PROXY_HOST_READ = \"\" # RDS Proxy username DB_RDS_PROXY_USER = \"\" # RDS Proxy password DB_RDS_PROXY_PASSWORD = \"\" Database Connection \u00b6 Connecting to the database is automatically handled when you execute your query. For Aurora Serverless (via Data API), this is nothing to worry about as the opening and closing of database connections is handled within Data API itself! Thus, one less worry about managing connection pools. For Aurora Provisioned (via RDS Proxy), a connection will be opened and closed per every query executed. While this works, it is not efficient as opening and closing a database connection will cost additional time (and money!). As such, specifically for RDS Proxy, you should make use of Lesgo's persistent connection method db.pConnect() . This should be handled at the Handler level as much as possible. Persistent Connection for RDS Proxy \u00b6 // src/handlers/utils/ping.js import middy from \"@middy/core\" ; import httpMiddleware from \"Middlewares/httpMiddleware\" ; import ping from \"Core/utils/ping\" ; import db from \"Utils/db\" ; const originalHandler = async ( event ) => { await db . pConnect (); return ping ( event . input ); }; export const handler = middy ( originalHandler ); handler . use ( httpMiddleware ({ db })); Notice the passing of the db object into httpMiddleware() . This is important to allow httpMiddleware to disconnect from RDS Proxy at the end of the lambda execution. Without doing so, you will encounter lambda timeout issues as the db connection is still open. Should you want to handle the closing of the db connection yourself and without using any of Lesgo!'s middlewares, you can do so as shown below. // src/handlers/utils/ping.js import middy from \"@middy/core\" ; import httpMiddleware from \"Middlewares/httpMiddleware\" ; import ping from \"Core/utils/ping\" ; import db from \"Utils/db\" ; const originalHandler = async ( event ) => { await db . pConnect (); try { const resp = await ping ( event . input ); return resp ; } catch ( err ) { throw err ; } finally { db . end (); } }; export const handler = middy ( originalHandler ); handler . use (); The finally in try catch is important to allow for a safe disconnection of the db. Running Database Queries \u00b6 Retrieving All Rows \u00b6 db.select() will return a promised array of objects. db . select ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const data = await db . select ( \"SELECT * FROM users WHERE is_deleted = :isDeleted\" , { isDeleted : 0 , } ); Retrieving a Single Row \u00b6 db.selectFirst() will return a promised object of a single record. db . selectFirst ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const data = await db . selectFirst ( \"SELECT * FROM users WHERE id = :id\" , { id : 1 , }); Retrieving Paginated Rows \u00b6 db.selectPaginate() will return a promised object with pagination data and itemized rows. db . selectPaginate ( sql : String , sqlParams : Object , perPage ?: Number = 10 , currentPage ?: Number = 1 , total ?: Number = null , connectionOpts ?: Object = {} ); Note When total is not provided, db.selectPaginate() will run 2 separate queries to first fetch all the record count, followed by the actual query with OFFSET and LIMIT . It is strongly advisable to pass along the total for best performance. Usage import db from \"Utils/db\" ; const data = await db . selectPaginate ( \"SELECT * FROM users WHERE is_deleted = :isDeleted\" , { isDeleted : 0 , }, { perPage : 1 , currentPage : 1 , total : 25 , } ); Inserting a Single Record \u00b6 db.insert() will insert a new record and return only the newly inserted primary key. db . insert ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const insertId = await db . insert ( \"INSERT INTO users(username,email) VALUES (:username, :email)\" , { username : \"John\" , email : \"john@mail.com\" , } ); A much better approach to inserting records is to first validate the fields and then inserting it with Utils/prepSQLInsertParams . import prepSQLInsertParams from \"Utils/prepSQLInsertParams\" ; import validateFields from \"Utils/validateFields\" ; import db from \"Utils/db\" ; const validFields = [ { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; let validated = validateFields ({ ... params }, validFields ); const { insertColumns , insertValues , insertFields } = prepSQLInsertParams ( validated , validFields ); await db . insert ( `INSERT INTO users( ${ insertColumns } ) VALUES( ${ insertValues } )` , insertFields ); Learn more about Utils/validateFields and Utils/prepSQLInsertParams . Updating an Existing Record \u00b6 db.update() will update an existing record and throw an Error if no record found for update. db . update ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const insertId = await db . update ( \"UPDATE users SET username=:username, email=:email, updated_at=now()) WHERE id=:id\" , { id : 1 , username : \"John\" , email : \"john@mail.com\" , } ); As with insert, updatating an existing record is best done with Utils/prepSQLUpdateParams . import prepSQLUpdateParams from \"Utils/prepSQLUpdateParams\" ; import validateFields from \"Utils/validateFields\" ; import db from \"Utils/db\" ; const validFields = [ { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; const params = { username : \"John\" , email : \"john@mail.com\" , }; let validated = validateFields ( params , validFields ); const { updateColumnValues , wherePrimaryKey , updateFields } = prepSQLUpdateParams ( validated , validFields ); await db . update ( `UPDATE users SET ${ updateColumnValues } , updated_at=NOW() WHERE ${ wherePrimaryKey } ` , updateFields ); Learn more about Utils/prepSQLUpdateParams . Raw Query \u00b6 All of the above executes db.query() . You may also execute your queries directly and get a raw response. db . query ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const data = await db . query ( \"SELECT * FROM users WHERE id = :id\" , { id : 1 , });","title":"RDS Aurora"},{"location":"database/rds-aurora/#aws-rds-aurora","text":"MySQL and PostgreSQL-compatible relational database built for the cloud. Performance and availability of commercial-grade databases at 1/10th the cost.","title":"AWS RDS Aurora"},{"location":"database/rds-aurora/#configuration","text":"The database configuration for your application is located at src/config/db.js . Or copy this file to that path.","title":"Configuration"},{"location":"database/rds-aurora/#aurora-serverless","text":"Note As Lesgo! establishes connection to Aurora Serverless via the Data API, prior setup and storing of the credentials on AWS Secret Manager is required. Find out more . For Aurora Serverless via Data API, create a connections.dataApi configuration as shown below. // src/config/db.js export default { default : \"dataApi\" , connections : { dataApi : { secretArn : process . env . DB_SECRET_ARN || \"secretArnDataApi\" , secretCommandArn : process . env . DB_SECRET_COMMAND_ARN || \"secretCommandArnDataApi\" , resourceArn : process . env . DB_RESOURCE_ARN || \"resourceArnDataApi\" , database : process . env . DB_NAME || \"databaseDataApi\" , }, }, }; You may also simply update the respective environment files in config/environments/.env.* as such: # AWS Secret Manager ARN to allow app db user connect to the specified db DB_SECRET_ARN = \"\" # AWS Secret Manager ARN to allow app command db user connect to the specified db # for running \"command\" like functions like database schema migration DB_SECRET_COMMAND_ARN = \"\" # AWS Secret Manager ARN for the Aurora Serverless database cluster DB_RESOURCE_ARN = \"\" # Database name to connect to DB_NAME = \"\"","title":"Aurora Serverless"},{"location":"database/rds-aurora/#aurora-provisioned","text":"Note As Lesgo! establishes connection to Aurora Provisioned via the RDS Proxy, prior setup of the RDS Proxy is required. Find out more . For Aurora Provisioned via RDS Proxy, create a connections.rdsProxy configuration as shown below. // src/config/db.js export default { default : \"rdsProxy\" , connections : { rdsProxy : { host : process . env . DB_RDS_PROXY_HOST || \"rds-cluster-proxy.proxy-ek9srsfbg2xc.us-west-2.rds.amazonaws.com\" , user : process . env . DB_RDS_PROXY_USER || \"proxyUser\" , password : process . env . DB_RDS_PROXY_PASSWORD || \"proxyPass\" , database : process . env . DB_NAME || \"dbname\" , }, rdsProxyRead : { host : process . env . DB_RDS_PROXY_HOST_READ || process . env . DB_RDS_PROXY_HOST || \"rds-cluster-proxy-read-only.proxy-ek9srsfbg2xc.us-west-2.rds.amazonaws.com\" , user : process . env . DB_RDS_PROXY_USER_READ || process . env . DB_RDS_PROXY_USER || \"proxyUser\" , password : process . env . DB_RDS_PROXY_PASSWORD_READ || process . env . DB_RDS_PROXY_PASSWORD || \"proxyPass\" , database : process . env . DB_NAME || \"dbname\" , }, }, }; You may also simply update the respective environment files in config/environments/env.* as such: # config/environments/.env.* # Domain host of the RDS Proxy DB_RDS_PROXY_HOST = \"\" # Domain host of the RDS Proxy for read-only connection DB_RDS_PROXY_HOST_READ = \"\" # RDS Proxy username DB_RDS_PROXY_USER = \"\" # RDS Proxy password DB_RDS_PROXY_PASSWORD = \"\"","title":"Aurora Provisioned"},{"location":"database/rds-aurora/#database-connection","text":"Connecting to the database is automatically handled when you execute your query. For Aurora Serverless (via Data API), this is nothing to worry about as the opening and closing of database connections is handled within Data API itself! Thus, one less worry about managing connection pools. For Aurora Provisioned (via RDS Proxy), a connection will be opened and closed per every query executed. While this works, it is not efficient as opening and closing a database connection will cost additional time (and money!). As such, specifically for RDS Proxy, you should make use of Lesgo's persistent connection method db.pConnect() . This should be handled at the Handler level as much as possible.","title":"Database Connection"},{"location":"database/rds-aurora/#persistent-connection-for-rds-proxy","text":"// src/handlers/utils/ping.js import middy from \"@middy/core\" ; import httpMiddleware from \"Middlewares/httpMiddleware\" ; import ping from \"Core/utils/ping\" ; import db from \"Utils/db\" ; const originalHandler = async ( event ) => { await db . pConnect (); return ping ( event . input ); }; export const handler = middy ( originalHandler ); handler . use ( httpMiddleware ({ db })); Notice the passing of the db object into httpMiddleware() . This is important to allow httpMiddleware to disconnect from RDS Proxy at the end of the lambda execution. Without doing so, you will encounter lambda timeout issues as the db connection is still open. Should you want to handle the closing of the db connection yourself and without using any of Lesgo!'s middlewares, you can do so as shown below. // src/handlers/utils/ping.js import middy from \"@middy/core\" ; import httpMiddleware from \"Middlewares/httpMiddleware\" ; import ping from \"Core/utils/ping\" ; import db from \"Utils/db\" ; const originalHandler = async ( event ) => { await db . pConnect (); try { const resp = await ping ( event . input ); return resp ; } catch ( err ) { throw err ; } finally { db . end (); } }; export const handler = middy ( originalHandler ); handler . use (); The finally in try catch is important to allow for a safe disconnection of the db.","title":"Persistent Connection for RDS Proxy"},{"location":"database/rds-aurora/#running-database-queries","text":"","title":"Running Database Queries"},{"location":"database/rds-aurora/#retrieving-all-rows","text":"db.select() will return a promised array of objects. db . select ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const data = await db . select ( \"SELECT * FROM users WHERE is_deleted = :isDeleted\" , { isDeleted : 0 , } );","title":"Retrieving All Rows"},{"location":"database/rds-aurora/#retrieving-a-single-row","text":"db.selectFirst() will return a promised object of a single record. db . selectFirst ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const data = await db . selectFirst ( \"SELECT * FROM users WHERE id = :id\" , { id : 1 , });","title":"Retrieving a Single Row"},{"location":"database/rds-aurora/#retrieving-paginated-rows","text":"db.selectPaginate() will return a promised object with pagination data and itemized rows. db . selectPaginate ( sql : String , sqlParams : Object , perPage ?: Number = 10 , currentPage ?: Number = 1 , total ?: Number = null , connectionOpts ?: Object = {} ); Note When total is not provided, db.selectPaginate() will run 2 separate queries to first fetch all the record count, followed by the actual query with OFFSET and LIMIT . It is strongly advisable to pass along the total for best performance. Usage import db from \"Utils/db\" ; const data = await db . selectPaginate ( \"SELECT * FROM users WHERE is_deleted = :isDeleted\" , { isDeleted : 0 , }, { perPage : 1 , currentPage : 1 , total : 25 , } );","title":"Retrieving Paginated Rows"},{"location":"database/rds-aurora/#inserting-a-single-record","text":"db.insert() will insert a new record and return only the newly inserted primary key. db . insert ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const insertId = await db . insert ( \"INSERT INTO users(username,email) VALUES (:username, :email)\" , { username : \"John\" , email : \"john@mail.com\" , } ); A much better approach to inserting records is to first validate the fields and then inserting it with Utils/prepSQLInsertParams . import prepSQLInsertParams from \"Utils/prepSQLInsertParams\" ; import validateFields from \"Utils/validateFields\" ; import db from \"Utils/db\" ; const validFields = [ { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; let validated = validateFields ({ ... params }, validFields ); const { insertColumns , insertValues , insertFields } = prepSQLInsertParams ( validated , validFields ); await db . insert ( `INSERT INTO users( ${ insertColumns } ) VALUES( ${ insertValues } )` , insertFields ); Learn more about Utils/validateFields and Utils/prepSQLInsertParams .","title":"Inserting a Single Record"},{"location":"database/rds-aurora/#updating-an-existing-record","text":"db.update() will update an existing record and throw an Error if no record found for update. db . update ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const insertId = await db . update ( \"UPDATE users SET username=:username, email=:email, updated_at=now()) WHERE id=:id\" , { id : 1 , username : \"John\" , email : \"john@mail.com\" , } ); As with insert, updatating an existing record is best done with Utils/prepSQLUpdateParams . import prepSQLUpdateParams from \"Utils/prepSQLUpdateParams\" ; import validateFields from \"Utils/validateFields\" ; import db from \"Utils/db\" ; const validFields = [ { key : \"username\" , type : \"string\" , required : true }, { key : \"email\" , type : \"string\" , required : true }, ]; const params = { username : \"John\" , email : \"john@mail.com\" , }; let validated = validateFields ( params , validFields ); const { updateColumnValues , wherePrimaryKey , updateFields } = prepSQLUpdateParams ( validated , validFields ); await db . update ( `UPDATE users SET ${ updateColumnValues } , updated_at=NOW() WHERE ${ wherePrimaryKey } ` , updateFields ); Learn more about Utils/prepSQLUpdateParams .","title":"Updating an Existing Record"},{"location":"database/rds-aurora/#raw-query","text":"All of the above executes db.query() . You may also execute your queries directly and get a raw response. db . query ( sql : String , sqlParams : Object , connectionOpts ?: Object = {} ); Usage import db from \"Utils/db\" ; const data = await db . query ( \"SELECT * FROM users WHERE id = :id\" , { id : 1 , });","title":"Raw Query"},{"location":"getting-started/available-scripts/","text":"Available Scripts \u00b6 These are the available scripts within Lesgo! Framework Run lint \u00b6 npm run lint Run lint fix \u00b6 npm run lint-fix Test build with Jest \u00b6 npm test Run code coverage report \u00b6 npm run coverage Info The code coverage report will be made available in the coverage directory. Open the index.html to view the Code Coverage Report. It also creates a Test Coverage Report and can be found in coverage/test-report directory.","title":"Available Scripts"},{"location":"getting-started/available-scripts/#available-scripts","text":"These are the available scripts within Lesgo! Framework","title":"Available Scripts"},{"location":"getting-started/available-scripts/#run-lint","text":"npm run lint","title":"Run lint"},{"location":"getting-started/available-scripts/#run-lint-fix","text":"npm run lint-fix","title":"Run lint fix"},{"location":"getting-started/available-scripts/#test-build-with-jest","text":"npm test","title":"Test build with Jest"},{"location":"getting-started/available-scripts/#run-code-coverage-report","text":"npm run coverage Info The code coverage report will be made available in the coverage directory. Open the index.html to view the Code Coverage Report. It also creates a Test Coverage Report and can be found in coverage/test-report directory.","title":"Run code coverage report"},{"location":"getting-started/deployment/","text":"Deployment \u00b6 Serverless Framework handles most of the deployment tasks. Lesgo! uses its own deployment script to allow for a more custom deployment process. Deploy Entire Application \u00b6 This command will deploy the entire application to a specific environment. npm run deploy -- -s { environment } Example deploy \u00b6 npm run deploy -- -s dev Deploy Single Function \u00b6 This command will deploy only a single function to a specific environment. npm run deploy -- -s { environment } -f { function_name } Example deploy \u00b6 npm run deploy -- -s dev -f ping Other Available Commands \u00b6 These commands are also available. Invoke a function \u00b6 This command will invoke/trigger a single function. npm run invoke -- -s { environment } -f { function_name } # Example npm run invoke -- -s dev -f ping Tail log of a function \u00b6 This command allows you to tail the log of a single function. npm run logs -- -s { environment } -f { function_name } # Example npm run logs -- -s dev -f ping Build bundle without deployment \u00b6 This command allows you to build the bundle without doing actual deployment. This might be useful to note the created bundle files and sizes. npm run build -- -s { environment } # Example npm run build -- -s dev Destroy \u00b6 Destroy everything, leave nothing behind. DANGER! Note that this action is non-reversible! Everything will disappear from AWS. npm run destroy -- -s { environment } # Example npm run destroy -- -s dev","title":"Deployment"},{"location":"getting-started/deployment/#deployment","text":"Serverless Framework handles most of the deployment tasks. Lesgo! uses its own deployment script to allow for a more custom deployment process.","title":"Deployment"},{"location":"getting-started/deployment/#deploy-entire-application","text":"This command will deploy the entire application to a specific environment. npm run deploy -- -s { environment }","title":"Deploy Entire Application"},{"location":"getting-started/deployment/#example-deploy","text":"npm run deploy -- -s dev","title":"Example deploy"},{"location":"getting-started/deployment/#deploy-single-function","text":"This command will deploy only a single function to a specific environment. npm run deploy -- -s { environment } -f { function_name }","title":"Deploy Single Function"},{"location":"getting-started/deployment/#example-deploy_1","text":"npm run deploy -- -s dev -f ping","title":"Example deploy"},{"location":"getting-started/deployment/#other-available-commands","text":"These commands are also available.","title":"Other Available Commands"},{"location":"getting-started/deployment/#invoke-a-function","text":"This command will invoke/trigger a single function. npm run invoke -- -s { environment } -f { function_name } # Example npm run invoke -- -s dev -f ping","title":"Invoke a function"},{"location":"getting-started/deployment/#tail-log-of-a-function","text":"This command allows you to tail the log of a single function. npm run logs -- -s { environment } -f { function_name } # Example npm run logs -- -s dev -f ping","title":"Tail log of a function"},{"location":"getting-started/deployment/#build-bundle-without-deployment","text":"This command allows you to build the bundle without doing actual deployment. This might be useful to note the created bundle files and sizes. npm run build -- -s { environment } # Example npm run build -- -s dev","title":"Build bundle without deployment"},{"location":"getting-started/deployment/#destroy","text":"Destroy everything, leave nothing behind. DANGER! Note that this action is non-reversible! Everything will disappear from AWS. npm run destroy -- -s { environment } # Example npm run destroy -- -s dev","title":"Destroy"},{"location":"getting-started/installation/","text":"Installation \u00b6 A lightweight node.js boilerplate framework for serverless architecture \u00b6 Bootstrap your next serverless microservice with a light-weight node.js app built on top of the Serverless Framework on AWS. Why Lesgo! Framework \u00b6 Like any other frameworks out there, we built this Framework because we couldn't find one that fits our needs. We believe that a framework for the Serverless Architecture should fit the following criteria: Super lightweight . The bundled lambda function should only bundle what is necessarily required by the function, and nothing else. This is why we chose the Serverless Framework as the basic building block for this framework. It provides the necessary tools to build, bundle, and deploy direct to AWS via CloudFormation, while still allowing the option to bundle each function individually. Easy to understand file structure . Most of our file structure, scripts, and helper functions is inspired from the Laravel Framework. The primary reason being that all the original developers and current maintainers have years of experience building applications on Taylor Otwell's Laravel Framework. If you know Laravel, you will know Lesgo! Highly adaptable for any use case . We have built multiple microservices for the last 3 years from a simple \"Unique Name Generator\", to a process-intensive \"Photo Processor\" and \"Image Moderation\", to complex projects building a Social Network App using this very same framework! Continous upgrades . As long as we continue to use this framework, we will continue to maintain and expand its functionalities. This framework will continue to grow with us. We take the learnings from our other microservices and upgrade this framework accordingly. Quick Start \u00b6 Prerequisites Install Serverless Framework globally with: npm install -g serverless . Refer to https://serverless.com/framework/docs/getting-started/ for additional info. Create Serverless project: sls create --template-url https://github.com/reflex-media/lesgo-lite/tree/master --path my-service cd my-service Install dependencies: npm install Start local: npm start Access local url via browser or Postman: http://localhost:8181/ping . Configuration \u00b6 There are 2 levels of configurations for the Lesgo! framework. The project (serverless) configurations are stored in config/ directory as .yml files. These configuration files affect your project set up and build. The application configurations are stored in src/config/ directory as .js files (We'll move to TypeScript soon, we promise!). These are application/business specific configurations. Each configuration is documented below, so feel free to look through the files and get familiar with the options relevant to you. Environment Configuration \u00b6 It is often helpful to have different configuration values based on the environment where the application is running. For example, you may wish to use a different SQS queue locally than you do on your production server. To make this happen, Lesgo! uses the Serverless DOTenv plugin. DOTenv files are stored in config/environments/ directory. The supported environments are currently local , dev , sandbox , prod . These environment files can be committed to the source control. To overwrite for your local build, you may create a local DOTenv as such example: .env.dev.local . This will allow you to overwrite the existing .env.dev without having to commit it. Available Environment Configurations \u00b6 # Declare the environment to deploy to APP_ENV = \"dev\" # Enable/disable debug mode APP_DEBUG =true # Determine the region to deploy to AWS_ACCOUNT_REGION = \"us-west-1\" # This name needs to match the aws credentials profile on your local machine AWS_ACCOUNT_PROFILE = \"slsDevProfile\" # Set the default timeout for all lambda functions AWS_LAMBDA_TIMEOUT =3 # Set the default memory size for all lambda functions AWS_LAMBDA_MEMORY_SIZE =128 # Set the default retention period for all cloudwatch logs AWS_LOG_RETENTION_DAYS =7 # Maximum size before gzip compression for response AWS_APIGATEWAY_COMPRESSION_MAX_BYTES =","title":"Installation"},{"location":"getting-started/installation/#installation","text":"","title":"Installation"},{"location":"getting-started/installation/#a-lightweight-nodejs-boilerplate-framework-for-serverless-architecture","text":"Bootstrap your next serverless microservice with a light-weight node.js app built on top of the Serverless Framework on AWS.","title":"A lightweight node.js boilerplate framework for serverless architecture"},{"location":"getting-started/installation/#why-lesgo-framework","text":"Like any other frameworks out there, we built this Framework because we couldn't find one that fits our needs. We believe that a framework for the Serverless Architecture should fit the following criteria: Super lightweight . The bundled lambda function should only bundle what is necessarily required by the function, and nothing else. This is why we chose the Serverless Framework as the basic building block for this framework. It provides the necessary tools to build, bundle, and deploy direct to AWS via CloudFormation, while still allowing the option to bundle each function individually. Easy to understand file structure . Most of our file structure, scripts, and helper functions is inspired from the Laravel Framework. The primary reason being that all the original developers and current maintainers have years of experience building applications on Taylor Otwell's Laravel Framework. If you know Laravel, you will know Lesgo! Highly adaptable for any use case . We have built multiple microservices for the last 3 years from a simple \"Unique Name Generator\", to a process-intensive \"Photo Processor\" and \"Image Moderation\", to complex projects building a Social Network App using this very same framework! Continous upgrades . As long as we continue to use this framework, we will continue to maintain and expand its functionalities. This framework will continue to grow with us. We take the learnings from our other microservices and upgrade this framework accordingly.","title":"Why Lesgo! Framework"},{"location":"getting-started/installation/#quick-start","text":"Prerequisites Install Serverless Framework globally with: npm install -g serverless . Refer to https://serverless.com/framework/docs/getting-started/ for additional info. Create Serverless project: sls create --template-url https://github.com/reflex-media/lesgo-lite/tree/master --path my-service cd my-service Install dependencies: npm install Start local: npm start Access local url via browser or Postman: http://localhost:8181/ping .","title":"Quick Start"},{"location":"getting-started/installation/#configuration","text":"There are 2 levels of configurations for the Lesgo! framework. The project (serverless) configurations are stored in config/ directory as .yml files. These configuration files affect your project set up and build. The application configurations are stored in src/config/ directory as .js files (We'll move to TypeScript soon, we promise!). These are application/business specific configurations. Each configuration is documented below, so feel free to look through the files and get familiar with the options relevant to you.","title":"Configuration"},{"location":"getting-started/installation/#environment-configuration","text":"It is often helpful to have different configuration values based on the environment where the application is running. For example, you may wish to use a different SQS queue locally than you do on your production server. To make this happen, Lesgo! uses the Serverless DOTenv plugin. DOTenv files are stored in config/environments/ directory. The supported environments are currently local , dev , sandbox , prod . These environment files can be committed to the source control. To overwrite for your local build, you may create a local DOTenv as such example: .env.dev.local . This will allow you to overwrite the existing .env.dev without having to commit it.","title":"Environment Configuration"},{"location":"getting-started/installation/#available-environment-configurations","text":"# Declare the environment to deploy to APP_ENV = \"dev\" # Enable/disable debug mode APP_DEBUG =true # Determine the region to deploy to AWS_ACCOUNT_REGION = \"us-west-1\" # This name needs to match the aws credentials profile on your local machine AWS_ACCOUNT_PROFILE = \"slsDevProfile\" # Set the default timeout for all lambda functions AWS_LAMBDA_TIMEOUT =3 # Set the default memory size for all lambda functions AWS_LAMBDA_MEMORY_SIZE =128 # Set the default retention period for all cloudwatch logs AWS_LOG_RETENTION_DAYS =7 # Maximum size before gzip compression for response AWS_APIGATEWAY_COMPRESSION_MAX_BYTES =","title":"Available Environment Configurations"},{"location":"getting-started/structure/","text":"Directory Structure \u00b6 \u251c\u2500\u2500 config | \u251c\u2500\u2500 environments | | \u251c\u2500\u2500 .env | | \u251c\u2500\u2500 .env.local | | \u251c\u2500\u2500 .env.dev | | \u251c\u2500\u2500 .env.sandbox | | \u2514\u2500\u2500 .env.prod | \u251c\u2500\u2500 functions | \u251c\u2500\u2500 resources | \u2514\u2500\u2500 utils \u251c\u2500\u2500 documents \u251c\u2500\u2500 src | \u251c\u2500\u2500 config | \u251c\u2500\u2500 data | \u251c\u2500\u2500 core | \u251c\u2500\u2500 exceptions | \u251c\u2500\u2500 handlers | \u251c\u2500\u2500 middlewares | \u251c\u2500\u2500 models | \u251c\u2500\u2500 services | \u2514\u2500\u2500 utils \u2514\u2500\u2500 tests The Config Directory \u00b6 The config/ directory contains the serverless configurations. The application-specific configs can be found in src/config/ directory instead. Environment Config \u00b6 The config/environments directory contains environment-specific configurations. The environment files are used for both deployment and within application code. You may overwrite env files during a deployment by adding a .local suffix e.g; .env.dev.local . This is useful for when you want to deploy to a specific environment but not wanting to overwrite committed values. .env : default environment, served as a local example. .env.local : local environment configuration. This should not be committed. .env.dev : development environment configuration. .env.sandbox : sandbox environment configuration. .env.prod : production environment configuration. Function Config \u00b6 The config/functions/ directory contains the available and declared Serverless functions. Resource Config \u00b6 The config/resources/ directory contains the available and declared Serverless resources. Util Config \u00b6 The config/utils/ directory contains additional Serverless configs where required. The Documents Directory \u00b6 The documents/ directory contains any documents outside of the application. One use case is to store the exported Postman Collection and Environment files here. The Source Directory \u00b6 The src/ directory contains the main source code for your application. Config Directory \u00b6 The src/config/ directory contains the application configurations. Data Directory \u00b6 The src/data/ directory to store mocked data or application schema. Core Directory \u00b6 The src/core/ directory contains your application's business / functional logic. Exception Directory \u00b6 The src/exceptions/ directory contains error classes. Handler Directory \u00b6 The src/handlers/ directory contains the entry point for all events. Middleware Directory \u00b6 The src/middlewares/ directory contains the request middlewares. Model Directory \u00b6 The src/models/ directory contains the Model for the application. Models is the gateway to the database / data store. Service Directory \u00b6 The src/services/ directory contains class-based services or modules, usually instantiated. These classes are usually made available in the src/utils/ as helper functions. Util Directory \u00b6 The src/utils/ directory contains helper functions. Test Directory \u00b6 The tests/ directory contains test .spec.js files for unit testing.","title":"Directory Structure"},{"location":"getting-started/structure/#directory-structure","text":"\u251c\u2500\u2500 config | \u251c\u2500\u2500 environments | | \u251c\u2500\u2500 .env | | \u251c\u2500\u2500 .env.local | | \u251c\u2500\u2500 .env.dev | | \u251c\u2500\u2500 .env.sandbox | | \u2514\u2500\u2500 .env.prod | \u251c\u2500\u2500 functions | \u251c\u2500\u2500 resources | \u2514\u2500\u2500 utils \u251c\u2500\u2500 documents \u251c\u2500\u2500 src | \u251c\u2500\u2500 config | \u251c\u2500\u2500 data | \u251c\u2500\u2500 core | \u251c\u2500\u2500 exceptions | \u251c\u2500\u2500 handlers | \u251c\u2500\u2500 middlewares | \u251c\u2500\u2500 models | \u251c\u2500\u2500 services | \u2514\u2500\u2500 utils \u2514\u2500\u2500 tests","title":"Directory Structure"},{"location":"getting-started/structure/#the-config-directory","text":"The config/ directory contains the serverless configurations. The application-specific configs can be found in src/config/ directory instead.","title":"The Config Directory"},{"location":"getting-started/structure/#environment-config","text":"The config/environments directory contains environment-specific configurations. The environment files are used for both deployment and within application code. You may overwrite env files during a deployment by adding a .local suffix e.g; .env.dev.local . This is useful for when you want to deploy to a specific environment but not wanting to overwrite committed values. .env : default environment, served as a local example. .env.local : local environment configuration. This should not be committed. .env.dev : development environment configuration. .env.sandbox : sandbox environment configuration. .env.prod : production environment configuration.","title":"Environment Config"},{"location":"getting-started/structure/#function-config","text":"The config/functions/ directory contains the available and declared Serverless functions.","title":"Function Config"},{"location":"getting-started/structure/#resource-config","text":"The config/resources/ directory contains the available and declared Serverless resources.","title":"Resource Config"},{"location":"getting-started/structure/#util-config","text":"The config/utils/ directory contains additional Serverless configs where required.","title":"Util Config"},{"location":"getting-started/structure/#the-documents-directory","text":"The documents/ directory contains any documents outside of the application. One use case is to store the exported Postman Collection and Environment files here.","title":"The Documents Directory"},{"location":"getting-started/structure/#the-source-directory","text":"The src/ directory contains the main source code for your application.","title":"The Source Directory"},{"location":"getting-started/structure/#config-directory","text":"The src/config/ directory contains the application configurations.","title":"Config Directory"},{"location":"getting-started/structure/#data-directory","text":"The src/data/ directory to store mocked data or application schema.","title":"Data Directory"},{"location":"getting-started/structure/#core-directory","text":"The src/core/ directory contains your application's business / functional logic.","title":"Core Directory"},{"location":"getting-started/structure/#exception-directory","text":"The src/exceptions/ directory contains error classes.","title":"Exception Directory"},{"location":"getting-started/structure/#handler-directory","text":"The src/handlers/ directory contains the entry point for all events.","title":"Handler Directory"},{"location":"getting-started/structure/#middleware-directory","text":"The src/middlewares/ directory contains the request middlewares.","title":"Middleware Directory"},{"location":"getting-started/structure/#model-directory","text":"The src/models/ directory contains the Model for the application. Models is the gateway to the database / data store.","title":"Model Directory"},{"location":"getting-started/structure/#service-directory","text":"The src/services/ directory contains class-based services or modules, usually instantiated. These classes are usually made available in the src/utils/ as helper functions.","title":"Service Directory"},{"location":"getting-started/structure/#util-directory","text":"The src/utils/ directory contains helper functions.","title":"Util Directory"},{"location":"getting-started/structure/#test-directory","text":"The tests/ directory contains test .spec.js files for unit testing.","title":"Test Directory"},{"location":"packages/firebase/","text":"Firebase Admin Service \u00b6 Lesgo! comes with a service wrapper of firebase-admin plugin Initialization \u00b6 import FirebaseAdmin from \"Services/FirebaseAdminService\" ; const serviceAccount = require ( \"path/to/serviceAccountKey.json\" ); const firebaseAdmin = new FirebaseAdmin ({ serviceAccount , projectName : \"databaseName\" }); Accessing Firebase Admin Client \u00b6 If ever needed you can also access the service instance directly through firebaseAdmin.app Available methods \u00b6 firebaseAdmin.getAllUsers \u00b6 This will fetch all users from firebase // Get at most 10 users starting from await firebaseAdmin . getAllUsers ( 10 , \"zUECpHuP5a63T9DNt64TeTrxqfV1WvM5IVe8cYZ9E9tSbhFOrw3QK2VPXJiLiYZo4dne5naMKnPPPYrUkUaYaJgPzfaV0gVj0EEdkiJvsdlreEShuogIs4zbdlLtqPQ8\" ); /** [ { uid: \"ly7vYiwWlpE1kAMw34mfPPkqiqaA\", email: \"jon@test.com\", password: \"jon1234\", username: \"jonsnow\", role: \"user\", lastSignInTime: null, creationTime: \"Mon, 08 Jul 2019 01:07:01 GMT\" }, { uid: \"8zaRodq7KcGfXh6Dg3r5ub3svBgM\", email: \"arya@test.com\", password: \"arya1234\", username: \"aryastark\", role: \"user\", lastSignInTime: \"Sat, 27 Jul 2019 01:07:01 GMT\", creationTime: \"Thu, 25 Jul 2019 01:07:01 GMT\" }, ... ] */ firebaseAdmin.createUser \u00b6 This allows you to create a new Firebase Authentication user await firebaseAdmin . createUser ({ uid : \"ly7vYiwWlpE1kAMw34mfPPkqiqaA\" , email : \"jon@test.com\" , password : \"jon1234\" , username : \"jonuser\" }); /** { uid: \"ly7vYiwWlpE1kAMw34mfPPkqiqaA\", email: \"jon@test.com\", password: \"jon1234\", username: \"jonuser\", role: \"user\", lastSignInTime: null, creationTime: \"Mon, 08 Jul 2019 01:07:01 GMT\" } */ firebaseAdmin.deleteUser \u00b6 This allows deleting existing users by their uid await firebaseAdmin . deleteUser ( \"qSE2pP4lr0Dfn0DfcDbeY6rqlwjd\" ); firebaseAdmin.delete \u00b6 This will render this app unusable and frees the resources of all associated services. await firebaseAdmin . delete ();","title":"Firebase"},{"location":"packages/firebase/#firebase-admin-service","text":"Lesgo! comes with a service wrapper of firebase-admin plugin","title":"Firebase Admin Service"},{"location":"packages/firebase/#initialization","text":"import FirebaseAdmin from \"Services/FirebaseAdminService\" ; const serviceAccount = require ( \"path/to/serviceAccountKey.json\" ); const firebaseAdmin = new FirebaseAdmin ({ serviceAccount , projectName : \"databaseName\" });","title":"Initialization"},{"location":"packages/firebase/#accessing-firebase-admin-client","text":"If ever needed you can also access the service instance directly through firebaseAdmin.app","title":"Accessing Firebase Admin Client"},{"location":"packages/firebase/#available-methods","text":"","title":"Available methods"},{"location":"packages/firebase/#firebaseadmingetallusers","text":"This will fetch all users from firebase // Get at most 10 users starting from await firebaseAdmin . getAllUsers ( 10 , \"zUECpHuP5a63T9DNt64TeTrxqfV1WvM5IVe8cYZ9E9tSbhFOrw3QK2VPXJiLiYZo4dne5naMKnPPPYrUkUaYaJgPzfaV0gVj0EEdkiJvsdlreEShuogIs4zbdlLtqPQ8\" ); /** [ { uid: \"ly7vYiwWlpE1kAMw34mfPPkqiqaA\", email: \"jon@test.com\", password: \"jon1234\", username: \"jonsnow\", role: \"user\", lastSignInTime: null, creationTime: \"Mon, 08 Jul 2019 01:07:01 GMT\" }, { uid: \"8zaRodq7KcGfXh6Dg3r5ub3svBgM\", email: \"arya@test.com\", password: \"arya1234\", username: \"aryastark\", role: \"user\", lastSignInTime: \"Sat, 27 Jul 2019 01:07:01 GMT\", creationTime: \"Thu, 25 Jul 2019 01:07:01 GMT\" }, ... ] */","title":"firebaseAdmin.getAllUsers"},{"location":"packages/firebase/#firebaseadmincreateuser","text":"This allows you to create a new Firebase Authentication user await firebaseAdmin . createUser ({ uid : \"ly7vYiwWlpE1kAMw34mfPPkqiqaA\" , email : \"jon@test.com\" , password : \"jon1234\" , username : \"jonuser\" }); /** { uid: \"ly7vYiwWlpE1kAMw34mfPPkqiqaA\", email: \"jon@test.com\", password: \"jon1234\", username: \"jonuser\", role: \"user\", lastSignInTime: null, creationTime: \"Mon, 08 Jul 2019 01:07:01 GMT\" } */","title":"firebaseAdmin.createUser"},{"location":"packages/firebase/#firebaseadmindeleteuser","text":"This allows deleting existing users by their uid await firebaseAdmin . deleteUser ( \"qSE2pP4lr0Dfn0DfcDbeY6rqlwjd\" );","title":"firebaseAdmin.deleteUser"},{"location":"packages/firebase/#firebaseadmindelete","text":"This will render this app unusable and frees the resources of all associated services. await firebaseAdmin . delete ();","title":"firebaseAdmin.delete"},{"location":"prologue/contribution-guide/","text":"Contribution Guide \u00b6 Interested in contributing to the Lesgo! framework? Want to report a bug? Before you do, please read the following guidelines. Source Repositories! \u00b6 The Lesgo! source code is managed on GitHub, and live on 3 separate repositories: Lesgo! Template This is the main serverless template that developers will in their own project. Lesgo-lite! Template An even lighter template with the bare essentials of the Lesgo! Template. Lesgo! Framework Most of the core logic exists in this npm package. Lesgo! Documentation Repository for this documentation. Submission context \u00b6 Got a question or problem? \u00b6 Submit an issue to our Github Repository and we'll try our best to follow-up. Found a bug? \u00b6 If you found a bug in the source code, you can help us by submitting an issue to the issue tracker in our Github Repository . Even better, you can submit a Pull Request with a fix. However, before doing so, please read the submission guidelines. Missing a feature? \u00b6 You can request a new feature by submitting an issue to our Github Repository . If you would like to implement a new feature, please submit an issue with a proposal for your work first, to be sure that it is of use for everyone, as the Lesgo! framework is highly opinionated. Please consider what kind of change it is: For a major feature, first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. Small features and bugs can be crafted and directly submitted as a Pull Request. However, there is no guarantee that your feature will make it into the master, as it's always a matter of opinion whether if benefits the overall functionality of the theme. Submission guidelines \u00b6 Submitting an issue \u00b6 Before you submit an issue, please search the issue tracker, maybe an issue for your problem already exists and the discussion might inform you of workarounds readily available. We want to fix all the issues as soon as possible, but before fixing a bug we need to reproduce and confirm it. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction scenario using the custom issue template. Please stick to the issue template. Unfortunately we are not able to investigate / fix bugs without a minimal reproduction scenario, so if we don't hear back from you we may close the issue. Submitting a Pull Request (PR) \u00b6 Search GitHub for an open or closed PR that relates to your submission. You don't want to duplicate effort. If you do not find a related issue or PR, go ahead. Development : Fork the project, set up the development environment, make your changes in a separate git branch and add descriptive messages to your commits. Pull Request : Commit your changes, push your branch to GitHub and send a PR to lesgo:develop. If we suggest changes, make the required updates, rebase your branch and push the changes to your GitHub repository, which will automatically update your PR. After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.","title":"Contribution Guide"},{"location":"prologue/contribution-guide/#contribution-guide","text":"Interested in contributing to the Lesgo! framework? Want to report a bug? Before you do, please read the following guidelines.","title":"Contribution Guide"},{"location":"prologue/contribution-guide/#source-repositories","text":"The Lesgo! source code is managed on GitHub, and live on 3 separate repositories: Lesgo! Template This is the main serverless template that developers will in their own project. Lesgo-lite! Template An even lighter template with the bare essentials of the Lesgo! Template. Lesgo! Framework Most of the core logic exists in this npm package. Lesgo! Documentation Repository for this documentation.","title":"Source Repositories!"},{"location":"prologue/contribution-guide/#submission-context","text":"","title":"Submission context"},{"location":"prologue/contribution-guide/#got-a-question-or-problem","text":"Submit an issue to our Github Repository and we'll try our best to follow-up.","title":"Got a question or problem?"},{"location":"prologue/contribution-guide/#found-a-bug","text":"If you found a bug in the source code, you can help us by submitting an issue to the issue tracker in our Github Repository . Even better, you can submit a Pull Request with a fix. However, before doing so, please read the submission guidelines.","title":"Found a bug?"},{"location":"prologue/contribution-guide/#missing-a-feature","text":"You can request a new feature by submitting an issue to our Github Repository . If you would like to implement a new feature, please submit an issue with a proposal for your work first, to be sure that it is of use for everyone, as the Lesgo! framework is highly opinionated. Please consider what kind of change it is: For a major feature, first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. Small features and bugs can be crafted and directly submitted as a Pull Request. However, there is no guarantee that your feature will make it into the master, as it's always a matter of opinion whether if benefits the overall functionality of the theme.","title":"Missing a feature?"},{"location":"prologue/contribution-guide/#submission-guidelines","text":"","title":"Submission guidelines"},{"location":"prologue/contribution-guide/#submitting-an-issue","text":"Before you submit an issue, please search the issue tracker, maybe an issue for your problem already exists and the discussion might inform you of workarounds readily available. We want to fix all the issues as soon as possible, but before fixing a bug we need to reproduce and confirm it. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction scenario using the custom issue template. Please stick to the issue template. Unfortunately we are not able to investigate / fix bugs without a minimal reproduction scenario, so if we don't hear back from you we may close the issue.","title":"Submitting an issue"},{"location":"prologue/contribution-guide/#submitting-a-pull-request-pr","text":"Search GitHub for an open or closed PR that relates to your submission. You don't want to duplicate effort. If you do not find a related issue or PR, go ahead. Development : Fork the project, set up the development environment, make your changes in a separate git branch and add descriptive messages to your commits. Pull Request : Commit your changes, push your branch to GitHub and send a PR to lesgo:develop. If we suggest changes, make the required updates, rebase your branch and push the changes to your GitHub repository, which will automatically update your PR. After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.","title":"Submitting a Pull Request (PR)"},{"location":"prologue/release-notes/","text":"","title":"Release Notes"},{"location":"security/vpc/","text":"VPC \u00b6 The entire application is configured to be deployed to its own custom VPC. VPCs gives you an isolated environment from the rest of your existing network. Default VPC \u00b6 Should you choose to use the default VPC, follow these steps: Comment out vpc.yml and lambda.yml resources in serverless.yml # - ${file(${self:custom.path.resources}/vpc.yml)} # - ${file(${self:custom.path.resources}/lambda.yml)} Comment out vpc in provider in serverless.yml # vpc: # securityGroupIds: # - Ref: LambdaSecurityGroup # subnetIds: # - Ref: PrivateSubnet1 # - Ref: PrivateSubnet2 This will now set your lambda and required resources within your own AWS default VPC. ElastiCache VPC Requirement Note that ElastiCache requires you to set a VPC and will no longer work once you use a default VPC. Connecting to existing VPC \u00b6 Coming soon...","title":"VPC"},{"location":"security/vpc/#vpc","text":"The entire application is configured to be deployed to its own custom VPC. VPCs gives you an isolated environment from the rest of your existing network.","title":"VPC"},{"location":"security/vpc/#default-vpc","text":"Should you choose to use the default VPC, follow these steps: Comment out vpc.yml and lambda.yml resources in serverless.yml # - ${file(${self:custom.path.resources}/vpc.yml)} # - ${file(${self:custom.path.resources}/lambda.yml)} Comment out vpc in provider in serverless.yml # vpc: # securityGroupIds: # - Ref: LambdaSecurityGroup # subnetIds: # - Ref: PrivateSubnet1 # - Ref: PrivateSubnet2 This will now set your lambda and required resources within your own AWS default VPC. ElastiCache VPC Requirement Note that ElastiCache requires you to set a VPC and will no longer work once you use a default VPC.","title":"Default VPC"},{"location":"security/vpc/#connecting-to-existing-vpc","text":"Coming soon...","title":"Connecting to existing VPC"}]}